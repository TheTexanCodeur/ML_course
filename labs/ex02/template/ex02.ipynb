{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss by MSE\n",
    "    # ***************************************************\n",
    "    \n",
    "    e = y - tx @ w\n",
    "\n",
    "    N = e.shape[0]\n",
    "    \n",
    "    return e.T @ e / (2 * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694.483365887085"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(y, tx, np.array([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    \n",
    "    for index0, w0 in enumerate(grid_w0):\n",
    "        for index1, w1 in enumerate(grid_w1):\n",
    "            losses[index0][index1] = compute_loss(y, tx, np.array([w0,w1]))\n",
    "            \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss for each combination of w0 and w1.\n",
    "    # ***************************************************\n",
    "    # raise NotImplementedError\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=42.424483146782485, w0*=66.66666666666669, w1*=16.666666666666686, execution time=0.005 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute gradient vector\n",
    "    # ***************************************************\n",
    "\n",
    "    e = y - tx @ w\n",
    "\n",
    "    return -1/y.shape[0] * tx.T @ e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.706078    6.52028757]\n",
      "[-23.293922    -3.47971243]\n"
     ]
    }
   ],
   "source": [
    "print(compute_gradient(y, tx,np.array([100,20])))\n",
    "print(compute_gradient(y, tx,np.array([50,10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "\n",
    "        gradient = compute_gradient(y,tx, w)\n",
    "\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        \n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "\n",
    "        w = w - gamma * gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.236712759168, w0=51.30574540147362, w1=9.435798704492344\n",
      "GD iter. 1/49: loss=265.30246210896, w0=66.69746902191567, w1=12.26653831584001\n",
      "GD iter. 2/49: loss=37.87837955044153, w0=71.31498610804833, w1=13.115760199244328\n",
      "GD iter. 3/49: loss=17.410212120174503, w0=72.70024123388814, w1=13.37052676426563\n",
      "GD iter. 4/49: loss=15.568077051450457, w0=73.11581777164007, w1=13.446956733772021\n",
      "GD iter. 5/49: loss=15.402284895265295, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.38736360120863, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.386020684743528, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.38589982226167, w0=73.29247935783843, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.3858889446383, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.3858879656522, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543452, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613665, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899983, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.385887868835754, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829974, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.385887868829453, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829409, w0=73.29392197370963, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.385887868829403, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829407, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829403, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.385887868829403, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.385887868829398, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.385887868829398, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.385887868829398, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829403, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.3858878688294, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.3858878688294, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.385887868829398, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.385887868829398, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.385887868829391, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829395, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.007 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf296e06c9d4fc7a42fbbb69ec9b82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    # ***************************************************\n",
    "\n",
    "    e = y - tx @ w\n",
    "\n",
    "    return -1/y.shape[0] * tx.T @ e\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        \n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "\n",
    "            gradient = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        \n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "\n",
    "        w = w - gamma * gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2792.236712759168, w0=7.785480977805733, w1=6.99815889401512\n",
      "SGD iter. 1/49: loss=2182.069078738145, w0=13.872545152747403, w1=5.496913784741607\n",
      "SGD iter. 2/49: loss=1812.6984383507217, w0=20.337427490387118, w1=9.994054191961386\n",
      "SGD iter. 3/49: loss=1423.655950047236, w0=26.0964448737077, w1=11.273752361100183\n",
      "SGD iter. 4/49: loss=1131.619941435427, w0=30.21645514942923, w1=10.137057416001685\n",
      "SGD iter. 5/49: loss=948.806634378508, w0=34.96517673466416, w1=14.60128723930053\n",
      "SGD iter. 6/49: loss=750.5612097778542, w0=38.9757506868135, w1=17.273209007172984\n",
      "SGD iter. 7/49: loss=611.44963720327, w0=41.73263447527221, w1=16.769506374985184\n",
      "SGD iter. 8/49: loss=518.8546951283587, w0=44.35337385317494, w1=18.06529348901924\n",
      "SGD iter. 9/49: loss=444.67732825064485, w0=48.03949845350603, w1=13.33692684209806\n",
      "SGD iter. 10/49: loss=334.2890361176181, w0=50.76084695614957, w1=9.778403459166197\n",
      "SGD iter. 11/49: loss=276.1054674494166, w0=53.66421283449782, w1=15.793799795375442\n",
      "SGD iter. 12/49: loss=210.726129027004, w0=54.67822052013292, w1=16.12866930726075\n",
      "SGD iter. 13/49: loss=192.1665449573595, w0=57.24507277625868, w1=18.269192919431667\n",
      "SGD iter. 14/49: loss=155.63823026123484, w0=58.60298026474592, w1=19.63454367129243\n",
      "SGD iter. 15/49: loss=142.23874620775968, w0=59.99725112441862, w1=20.960380530651367\n",
      "SGD iter. 16/49: loss=131.76681366231864, w0=62.330742386995034, w1=17.20539352585952\n",
      "SGD iter. 17/49: loss=82.42189130084778, w0=64.45520794408347, w1=16.553260864518794\n",
      "SGD iter. 18/49: loss=59.17067094289721, w0=65.57644284775486, w1=15.6041479955331\n",
      "SGD iter. 19/49: loss=47.422243343197394, w0=66.29060485969704, w1=15.863828835849079\n",
      "SGD iter. 20/49: loss=42.751118873828226, w0=66.81364523535413, w1=16.088533033493515\n",
      "SGD iter. 21/49: loss=39.7858538132668, w0=67.94121211172707, w1=14.82181872458441\n",
      "SGD iter. 22/49: loss=30.612264100391, w0=69.09312274345194, w1=14.442016459069109\n",
      "SGD iter. 23/49: loss=24.67225959196058, w0=70.3076395749157, w1=13.362753962082971\n",
      "SGD iter. 24/49: loss=19.851668878492042, w0=70.13557239692625, w1=13.348230481628182\n",
      "SGD iter. 25/49: loss=20.382117735126172, w0=71.33730107341073, w1=11.901565793393916\n",
      "SGD iter. 26/49: loss=18.54534400932098, w0=72.18039724289153, w1=11.477796436314621\n",
      "SGD iter. 27/49: loss=18.00969039639463, w0=73.99624419268804, w1=12.934225189386048\n",
      "SGD iter. 28/49: loss=15.78129426607972, w0=73.05053029518191, w1=12.64438965388803\n",
      "SGD iter. 29/49: loss=15.764389704642078, w0=73.75193100383879, w1=12.809206364592196\n",
      "SGD iter. 30/49: loss=15.71556318688342, w0=73.19687718405632, w1=13.37569984795011\n",
      "SGD iter. 31/49: loss=15.39600602631573, w0=73.49297781858557, w1=12.898269618367307\n",
      "SGD iter. 32/49: loss=15.574737352367245, w0=74.01933718605909, w1=13.506341882881014\n",
      "SGD iter. 33/49: loss=15.649356027132349, w0=73.58774536356394, w1=14.261841410434666\n",
      "SGD iter. 34/49: loss=15.734916819814668, w0=73.75983532375584, w1=14.384371885221368\n",
      "SGD iter. 35/49: loss=15.903629840922493, w0=72.84655290825698, w1=13.625797757101045\n",
      "SGD iter. 36/49: loss=15.496627882562965, w0=72.30851260372857, w1=13.859830675079694\n",
      "SGD iter. 37/49: loss=15.943648648258684, w0=71.68765706571321, w1=13.874073863454505\n",
      "SGD iter. 38/49: loss=16.753691859901224, w0=72.65951441668598, w1=15.044744022380062\n",
      "SGD iter. 39/49: loss=16.811786295813935, w0=72.52527409115201, w1=14.933713555682337\n",
      "SGD iter. 40/49: loss=16.738357303824408, w0=70.87744284012696, w1=14.751098509320467\n",
      "SGD iter. 41/49: loss=19.113784913968832, w0=70.65815678742797, w1=14.62787993543064\n",
      "SGD iter. 42/49: loss=19.518661306815776, w0=70.80107685033379, w1=14.436579053409238\n",
      "SGD iter. 43/49: loss=18.95082320690795, w0=70.83793591685466, w1=14.43406843608841\n",
      "SGD iter. 44/49: loss=18.857219382718693, w0=70.57698188539887, w1=14.552166294227685\n",
      "SGD iter. 45/49: loss=19.65184830781141, w0=71.2943706891263, w1=14.402365755312015\n",
      "SGD iter. 46/49: loss=17.810635170198708, w0=71.60161226299164, w1=14.380015752131204\n",
      "SGD iter. 47/49: loss=17.22311702680728, w0=71.85111724821583, w1=14.491591830463387\n",
      "SGD iter. 48/49: loss=16.93868060324503, w0=71.88929189127741, w1=14.50350444744957\n",
      "SGD iter. 49/49: loss=16.89645578534041, w0=73.13388207308182, w1=14.43239357205664\n",
      "SGD: execution time=0.006 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6ad699ba754f2d9e2579a3b7b438ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD: execution time=0.000 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a0a8d19b194d94816b58bc1f5cacdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "    # ***************************************************\n",
    "\n",
    "    e = y - tx @ w\n",
    "\n",
    "    sign_e = np.sign(e)\n",
    "\n",
    "    return - tx.T @ sign_e / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute subgradient and loss\n",
    "        # ***************************************************\n",
    "\n",
    "        subgradient = compute_subgradient_mae(y,tx, w)\n",
    "\n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by subgradient\n",
    "        # ***************************************************\n",
    "\n",
    "        w = w - gamma * subgradient\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=2792.236712759168, w0=0.7, w1=4.98390217984479e-17\n",
      "SubGD iter. 1/499: loss=2741.175967357693, w0=1.4, w1=9.96780435968958e-17\n",
      "SubGD iter. 2/499: loss=2690.60522195622, w0=2.0999999999999996, w1=1.495170653953437e-16\n",
      "SubGD iter. 3/499: loss=2640.524476554747, w0=2.8, w1=1.993560871937916e-16\n",
      "SubGD iter. 4/499: loss=2590.9337311532727, w0=3.5, w1=2.491951089922395e-16\n",
      "SubGD iter. 5/499: loss=2541.8329857517983, w0=4.2, w1=2.990341307906874e-16\n",
      "SubGD iter. 6/499: loss=2493.2222403503247, w0=4.9, w1=3.4887315258913533e-16\n",
      "SubGD iter. 7/499: loss=2445.101494948852, w0=5.6000000000000005, w1=3.9871217438758325e-16\n",
      "SubGD iter. 8/499: loss=2397.470749547378, w0=6.300000000000001, w1=4.485511961860311e-16\n",
      "SubGD iter. 9/499: loss=2350.330004145904, w0=7.000000000000001, w1=4.98390217984479e-16\n",
      "SubGD iter. 10/499: loss=2303.679258744431, w0=7.700000000000001, w1=5.482292397829269e-16\n",
      "SubGD iter. 11/499: loss=2257.5185133429572, w0=8.4, w1=5.980682615813747e-16\n",
      "SubGD iter. 12/499: loss=2211.847767941484, w0=9.1, w1=6.479072833798226e-16\n",
      "SubGD iter. 13/499: loss=2166.6670225400103, w0=9.799999999999999, w1=6.977463051782705e-16\n",
      "SubGD iter. 14/499: loss=2121.9762771385363, w0=10.499999999999998, w1=7.475853269767183e-16\n",
      "SubGD iter. 15/499: loss=2077.7755317370625, w0=11.199999999999998, w1=7.974243487751662e-16\n",
      "SubGD iter. 16/499: loss=2034.064786335589, w0=11.899999999999997, w1=8.472633705736141e-16\n",
      "SubGD iter. 17/499: loss=1990.844040934116, w0=12.599999999999996, w1=8.97102392372062e-16\n",
      "SubGD iter. 18/499: loss=1948.1132955326423, w0=13.299999999999995, w1=9.469414141705099e-16\n",
      "SubGD iter. 19/499: loss=1905.8725501311683, w0=13.999999999999995, w1=9.967804359689578e-16\n",
      "SubGD iter. 20/499: loss=1864.1218047296957, w0=14.699999999999994, w1=1.0466194577674056e-15\n",
      "SubGD iter. 21/499: loss=1822.8610593282215, w0=15.399999999999993, w1=1.0964584795658535e-15\n",
      "SubGD iter. 22/499: loss=1782.0903139267477, w0=16.099999999999994, w1=1.1462975013643014e-15\n",
      "SubGD iter. 23/499: loss=1741.8095685252733, w0=16.799999999999994, w1=1.1961365231627492e-15\n",
      "SubGD iter. 24/499: loss=1702.0188231238, w0=17.499999999999993, w1=1.2459755449611971e-15\n",
      "SubGD iter. 25/499: loss=1662.7180777223266, w0=18.199999999999992, w1=1.295814566759645e-15\n",
      "SubGD iter. 26/499: loss=1623.9073323208536, w0=18.89999999999999, w1=1.3456535885580929e-15\n",
      "SubGD iter. 27/499: loss=1585.58658691938, w0=19.59999999999999, w1=1.3954926103565407e-15\n",
      "SubGD iter. 28/499: loss=1547.7558415179058, w0=20.29999999999999, w1=1.4453316321549886e-15\n",
      "SubGD iter. 29/499: loss=1510.4150961164319, w0=20.99999999999999, w1=1.4951706539534365e-15\n",
      "SubGD iter. 30/499: loss=1473.5643507149591, w0=21.69999999999999, w1=1.5450096757518843e-15\n",
      "SubGD iter. 31/499: loss=1437.2036053134855, w0=22.399999999999988, w1=1.5948486975503322e-15\n",
      "SubGD iter. 32/499: loss=1401.3328599120114, w0=23.099999999999987, w1=1.64468771934878e-15\n",
      "SubGD iter. 33/499: loss=1365.952114510538, w0=23.799999999999986, w1=1.694526741147228e-15\n",
      "SubGD iter. 34/499: loss=1331.0613691090646, w0=24.499999999999986, w1=1.7443657629456758e-15\n",
      "SubGD iter. 35/499: loss=1296.6606237075914, w0=25.199999999999985, w1=1.7942047847441237e-15\n",
      "SubGD iter. 36/499: loss=1262.7498783061174, w0=25.899999999999984, w1=1.8440438065425717e-15\n",
      "SubGD iter. 37/499: loss=1229.3291329046433, w0=26.599999999999984, w1=1.8938828283410198e-15\n",
      "SubGD iter. 38/499: loss=1196.3983875031702, w0=27.299999999999983, w1=1.943721850139468e-15\n",
      "SubGD iter. 39/499: loss=1163.9576421016966, w0=27.999999999999982, w1=1.993560871937916e-15\n",
      "SubGD iter. 40/499: loss=1132.0068967002233, w0=28.69999999999998, w1=2.043399893736364e-15\n",
      "SubGD iter. 41/499: loss=1100.5461512987492, w0=29.39999999999998, w1=2.093238915534812e-15\n",
      "SubGD iter. 42/499: loss=1069.5754058972757, w0=30.099859999999982, w1=0.0004404657703110964\n",
      "SubGD iter. 43/499: loss=1039.0947703997665, w0=30.799719999999983, w1=0.0008809315406200996\n",
      "SubGD iter. 44/499: loss=1009.1039391158672, w0=31.499579999999984, w1=0.0013213973109291028\n",
      "SubGD iter. 45/499: loss=979.6029120455776, w0=32.19929999999999, w1=0.002151200058877495\n",
      "SubGD iter. 46/499: loss=950.5921950374297, w0=32.899019999999986, w1=0.0029810028068258873\n",
      "SubGD iter. 47/499: loss=922.0710867962547, w0=33.59859999999998, w1=0.004238399708449467\n",
      "SubGD iter. 48/499: loss=894.0393825319986, w0=34.298039999999986, w1=0.005823822408870378\n",
      "SubGD iter. 49/499: loss=866.4981316019939, w0=34.99747999999999, w1=0.007409245109291289\n",
      "SubGD iter. 50/499: loss=839.4460994991547, w0=35.69691999999999, w1=0.0089946678097122\n",
      "SubGD iter. 51/499: loss=812.8832862234805, w0=36.39607999999999, w1=0.011248049853571786\n",
      "SubGD iter. 52/499: loss=786.8110265218195, w0=37.09495999999999, w1=0.014269124444782295\n",
      "SubGD iter. 53/499: loss=761.2273946584976, w0=37.793699999999994, w1=0.017663499462426263\n",
      "SubGD iter. 54/499: loss=736.1321497394629, w0=38.49215999999999, w1=0.02158797299124473\n",
      "SubGD iter. 55/499: loss=711.5277641117272, w0=39.19019999999999, w1=0.026549981650603474\n",
      "SubGD iter. 56/499: loss=687.4116050652237, w0=39.88739999999999, w1=0.033459020630995345\n",
      "SubGD iter. 57/499: loss=663.784609448966, w0=40.584039999999995, w1=0.04155352991367849\n",
      "SubGD iter. 58/499: loss=640.6461355436799, w0=41.28025999999999, w1=0.050807387878799175\n",
      "SubGD iter. 59/499: loss=617.9909106434975, w0=41.97507999999999, w1=0.06316953459274224\n",
      "SubGD iter. 60/499: loss=595.8226317443307, w0=42.667939999999994, w1=0.0797066345319705\n",
      "SubGD iter. 61/499: loss=574.1413523916066, w0=43.35925999999999, w1=0.09929003796967656\n",
      "SubGD iter. 62/499: loss=552.9457342202982, w0=44.04889999999999, w1=0.12249682042566928\n",
      "SubGD iter. 63/499: loss=532.2291483076054, w0=44.735739999999986, w1=0.15117673515155747\n",
      "SubGD iter. 64/499: loss=511.995699452433, w0=45.41991999999998, w1=0.18484712944090714\n",
      "SubGD iter. 65/499: loss=492.2426034218455, w0=46.10073999999998, w1=0.22490170464892528\n",
      "SubGD iter. 66/499: loss=472.96546531720816, w0=46.77847999999998, w1=0.27030807598911033\n",
      "SubGD iter. 67/499: loss=454.16440191211495, w0=47.45243999999998, w1=0.322056413136556\n",
      "SubGD iter. 68/499: loss=435.8389398960883, w0=48.119959999999985, w1=0.38436028435176006\n",
      "SubGD iter. 69/499: loss=417.99419328514784, w0=48.78257999999998, w1=0.4546014318707631\n",
      "SubGD iter. 70/499: loss=400.615589562689, w0=49.44141999999998, w1=0.5311991534379781\n",
      "SubGD iter. 71/499: loss=383.6888118502978, w0=50.094659999999976, w1=0.6167864550872899\n",
      "SubGD iter. 72/499: loss=367.21619897220626, w0=50.74159999999998, w1=0.7118294204258171\n",
      "SubGD iter. 73/499: loss=351.1989200489347, w0=51.382239999999975, w1=0.8163783816189731\n",
      "SubGD iter. 74/499: loss=335.6268066231411, w0=52.015879999999974, w1=0.9309819479181289\n",
      "SubGD iter. 75/499: loss=320.4987420090776, w0=52.64223999999997, w1=1.0560410394456805\n",
      "SubGD iter. 76/499: loss=305.8056780990886, w0=53.261179999999975, w1=1.1909782249708571\n",
      "SubGD iter. 77/499: loss=291.54775817252016, w0=53.87353999999998, w1=1.3354326069269926\n",
      "SubGD iter. 78/499: loss=277.70327269381255, w0=54.479039999999976, w1=1.4888591554232227\n",
      "SubGD iter. 79/499: loss=264.2760614314377, w0=55.07641999999998, w1=1.6526057998942567\n",
      "SubGD iter. 80/499: loss=251.26480314613454, w0=55.664699999999975, w1=1.82719991173866\n",
      "SubGD iter. 81/499: loss=238.67114612083802, w0=56.24345999999998, w1=2.013212915976338\n",
      "SubGD iter. 82/499: loss=226.48532072120543, w0=56.81479999999998, w1=2.207598649786131\n",
      "SubGD iter. 83/499: loss=214.6968934422441, w0=57.37633999999998, w1=2.411376270974589\n",
      "SubGD iter. 84/499: loss=203.3246289855163, w0=57.92975999999998, w1=2.6230481013706024\n",
      "SubGD iter. 85/499: loss=192.34820510872746, w0=58.47407999999998, w1=2.8433267790652352\n",
      "SubGD iter. 86/499: loss=181.76609626328104, w0=59.00957999999998, w1=3.072330965520481\n",
      "SubGD iter. 87/499: loss=171.56389561090168, w0=59.53569999999998, w1=3.310292494541028\n",
      "SubGD iter. 88/499: loss=161.73877516102613, w0=60.053559999999976, w1=3.555351748353952\n",
      "SubGD iter. 89/499: loss=152.28594836143915, w0=60.559939999999976, w1=3.8091706918861905\n",
      "SubGD iter. 90/499: loss=143.2227254863465, w0=61.057499999999976, w1=4.069720751434112\n",
      "SubGD iter. 91/499: loss=134.52487131791813, w0=61.547919999999976, w1=4.335508393727035\n",
      "SubGD iter. 92/499: loss=126.1784031596754, w0=62.02965999999998, w1=4.606989747001167\n",
      "SubGD iter. 93/499: loss=118.1902910438324, w0=62.502719999999975, w1=4.885020142516949\n",
      "SubGD iter. 94/499: loss=110.54527599508872, w0=62.96583999999997, w1=5.16875462665401\n",
      "SubGD iter. 95/499: loss=103.25653663589675, w0=63.41971999999997, w1=5.456484559032177\n",
      "SubGD iter. 96/499: loss=96.32191323278441, w0=63.86463999999997, w1=5.747997496770242\n",
      "SubGD iter. 97/499: loss=89.73127534937991, w0=64.30129999999997, w1=6.04322122396851\n",
      "SubGD iter. 98/499: loss=83.47021387099564, w0=64.72773999999997, w1=6.34035408083705\n",
      "SubGD iter. 99/499: loss=77.56084376992501, w0=65.14381999999996, w1=6.639945245906467\n",
      "SubGD iter. 100/499: loss=71.98917679161445, w0=65.54995999999996, w1=6.93975430625712\n",
      "SubGD iter. 101/499: loss=66.75588777663762, w0=65.94755999999995, w1=7.240382293155485\n",
      "SubGD iter. 102/499: loss=61.83502551121358, w0=66.33451999999996, w1=7.542759507922998\n",
      "SubGD iter. 103/499: loss=57.22623101138159, w0=66.71139999999995, w1=7.846017516367703\n",
      "SubGD iter. 104/499: loss=52.919945040979094, w0=67.07791999999995, w1=8.14916807677347\n",
      "SubGD iter. 105/499: loss=48.91257989136952, w0=67.43603999999995, w1=8.45047137864052\n",
      "SubGD iter. 106/499: loss=45.189911445554436, w0=67.78645999999995, w1=8.751045452661216\n",
      "SubGD iter. 107/499: loss=41.73210243602461, w0=68.12511999999995, w1=9.049215722253003\n",
      "SubGD iter. 108/499: loss=38.558795498095385, w0=68.45537999999995, w1=9.343976087699758\n",
      "SubGD iter. 109/499: loss=35.64378978904254, w0=68.77695999999995, w1=9.635092372673123\n",
      "SubGD iter. 110/499: loss=32.97791244484174, w0=69.08803999999995, w1=9.919493282073486\n",
      "SubGD iter. 111/499: loss=30.5681897850392, w0=69.38749999999995, w1=10.197623582279123\n",
      "SubGD iter. 112/499: loss=28.40200791663674, w0=69.67281999999994, w1=10.46806359361351\n",
      "SubGD iter. 113/499: loss=26.477092095534005, w0=69.94651999999995, w1=10.728826346302123\n",
      "SubGD iter. 114/499: loss=24.772125087144104, w0=70.20887999999995, w1=10.979299692022396\n",
      "SubGD iter. 115/499: loss=23.270661888801154, w0=70.45653999999995, w1=11.22039267925349\n",
      "SubGD iter. 116/499: loss=21.96351906109326, w0=70.69215999999994, w1=11.449066352016837\n",
      "SubGD iter. 117/499: loss=20.83223238377393, w0=70.91545999999994, w1=11.664512641643523\n",
      "SubGD iter. 118/499: loss=19.86190376143948, w0=71.12447999999993, w1=11.864387168309053\n",
      "SubGD iter. 119/499: loss=19.043765027666026, w0=71.31865999999994, w1=12.045105403559592\n",
      "SubGD iter. 120/499: loss=18.365766524623247, w0=71.49939999999994, w1=12.209836073166086\n",
      "SubGD iter. 121/499: loss=17.802335464007683, w0=71.66543999999993, w1=12.357476521898827\n",
      "SubGD iter. 122/499: loss=17.341571406734488, w0=71.81593999999993, w1=12.489808881940395\n",
      "SubGD iter. 123/499: loss=16.968057790272113, w0=71.95369999999993, w1=12.612418157319404\n",
      "SubGD iter. 124/499: loss=16.660085058332175, w0=72.08067999999993, w1=12.721366944472253\n",
      "SubGD iter. 125/499: loss=16.409409888159168, w0=72.19435999999993, w1=12.815458765817718\n",
      "SubGD iter. 126/499: loss=16.211022635570046, w0=72.29697999999993, w1=12.900592769395445\n",
      "SubGD iter. 127/499: loss=16.050524340148847, w0=72.38965999999994, w1=12.975769654280025\n",
      "SubGD iter. 128/499: loss=15.92171191616947, w0=72.47435999999993, w1=13.043963349302377\n",
      "SubGD iter. 129/499: loss=15.816667439315172, w0=72.55093999999994, w1=13.103277584601795\n",
      "SubGD iter. 130/499: loss=15.732750594848595, w0=72.62051999999994, w1=13.15603203518825\n",
      "SubGD iter. 131/499: loss=15.665007497656683, w0=72.68239999999994, w1=13.201870566969268\n",
      "SubGD iter. 132/499: loss=15.611465500171162, w0=72.73769999999995, w1=13.241365939188801\n",
      "SubGD iter. 133/499: loss=15.56898385267251, w0=72.78823999999994, w1=13.276636749385855\n",
      "SubGD iter. 134/499: loss=15.53436487949759, w0=72.83401999999994, w1=13.308112586749793\n",
      "SubGD iter. 135/499: loss=15.506366048557474, w0=72.87447999999993, w1=13.335151520405113\n",
      "SubGD iter. 136/499: loss=15.484302594407106, w0=72.91115999999994, w1=13.358430829065565\n",
      "SubGD iter. 137/499: loss=15.466495857924905, w0=72.94447999999994, w1=13.37925678085137\n",
      "SubGD iter. 138/499: loss=15.45198839447118, w0=72.97401999999994, w1=13.39640637690565\n",
      "SubGD iter. 139/499: loss=15.440526463961572, w0=73.00103999999993, w1=13.412189120459477\n",
      "SubGD iter. 140/499: loss=15.431057501410525, w0=73.02483999999993, w1=13.42527489531319\n",
      "SubGD iter. 141/499: loss=15.42357215362087, w0=73.04625999999993, w1=13.43622202132241\n",
      "SubGD iter. 142/499: loss=15.417501810513242, w0=73.06613999999993, w1=13.44744004660136\n",
      "SubGD iter. 143/499: loss=15.412350942597062, w0=73.08405999999994, w1=13.457856669598\n",
      "SubGD iter. 144/499: loss=15.408147736033623, w0=73.10029999999993, w1=13.46733516273498\n",
      "SubGD iter. 145/499: loss=15.404709207113253, w0=73.11401999999994, w1=13.47539362822033\n",
      "SubGD iter. 146/499: loss=15.402079560056096, w0=73.12619999999994, w1=13.482212864437999\n",
      "SubGD iter. 147/499: loss=15.39995632989821, w0=73.13697999999994, w1=13.487997256911566\n",
      "SubGD iter. 148/499: loss=15.398237583978949, w0=73.14747999999993, w1=13.493479439140359\n",
      "SubGD iter. 149/499: loss=15.396705264021351, w0=73.15699999999993, w1=13.49846827125447\n",
      "SubGD iter. 150/499: loss=15.39543757685667, w0=73.16595999999993, w1=13.502946804297236\n",
      "SubGD iter. 151/499: loss=15.394344923779366, w0=73.17365999999993, w1=13.506576029236358\n",
      "SubGD iter. 152/499: loss=15.393480169752522, w0=73.18009999999992, w1=13.509768665455214\n",
      "SubGD iter. 153/499: loss=15.392817281405945, w0=73.18597999999993, w1=13.51257146836669\n",
      "SubGD iter. 154/499: loss=15.392253464775905, w0=73.19143999999993, w1=13.515117410468962\n",
      "SubGD iter. 155/499: loss=15.391765905351514, w0=73.19605999999993, w1=13.517185961787792\n",
      "SubGD iter. 156/499: loss=15.391378487162793, w0=73.19969999999994, w1=13.51806993087439\n",
      "SubGD iter. 157/499: loss=15.391062410415051, w0=73.20291999999993, w1=13.51885413776712\n",
      "SubGD iter. 158/499: loss=15.390794587471166, w0=73.20599999999993, w1=13.519529839268976\n",
      "SubGD iter. 159/499: loss=15.390545720898293, w0=73.20907999999993, w1=13.520205540770833\n",
      "SubGD iter. 160/499: loss=15.390306797297946, w0=73.21201999999992, w1=13.521000216270622\n",
      "SubGD iter. 161/499: loss=15.390094178245397, w0=73.21495999999992, w1=13.52179489177041\n",
      "SubGD iter. 162/499: loss=15.389890834302014, w0=73.21747999999992, w1=13.52240720954705\n",
      "SubGD iter. 163/499: loss=15.38972098055961, w0=73.21985999999993, w1=13.522732908460993\n",
      "SubGD iter. 164/499: loss=15.389555839476193, w0=73.22181999999992, w1=13.522991164028843\n",
      "SubGD iter. 165/499: loss=15.389423742376843, w0=73.22363999999992, w1=13.523086524955914\n",
      "SubGD iter. 166/499: loss=15.389298304579594, w0=73.22503999999992, w1=13.522757010157502\n",
      "SubGD iter. 167/499: loss=15.389186651662131, w0=73.22643999999993, w1=13.52242749535909\n",
      "SubGD iter. 168/499: loss=15.389077067324676, w0=73.22783999999993, w1=13.522097980560677\n",
      "SubGD iter. 169/499: loss=15.388969551567218, w0=73.22895999999993, w1=13.522225963141349\n",
      "SubGD iter. 170/499: loss=15.38890159972614, w0=73.23007999999993, w1=13.52235394572202\n",
      "SubGD iter. 171/499: loss=15.3888349186646, w0=73.23119999999993, w1=13.522481928302692\n",
      "SubGD iter. 172/499: loss=15.388769508382602, w0=73.23189999999992, w1=13.523013495747128\n",
      "SubGD iter. 173/499: loss=15.38874872413336, w0=73.23273999999992, w1=13.523266279565897\n",
      "SubGD iter. 174/499: loss=15.388707956208917, w0=73.23329999999991, w1=13.523741235074873\n",
      "SubGD iter. 175/499: loss=15.388694650017525, w0=73.23399999999991, w1=13.523937406958183\n",
      "SubGD iter. 176/499: loss=15.388661116070384, w0=73.2345599999999, w1=13.523888604707798\n",
      "SubGD iter. 177/499: loss=15.388625559461882, w0=73.23497999999991, w1=13.524118586083079\n",
      "SubGD iter. 178/499: loss=15.388610901762982, w0=73.23539999999991, w1=13.52434856745836\n",
      "SubGD iter. 179/499: loss=15.388596473355513, w0=73.23581999999992, w1=13.52457854883364\n",
      "SubGD iter. 180/499: loss=15.388582274239475, w0=73.23623999999992, w1=13.52480853020892\n",
      "SubGD iter. 181/499: loss=15.388568304414875, w0=73.23651999999993, w1=13.524964267899371\n",
      "SubGD iter. 182/499: loss=15.388559227943118, w0=73.23679999999993, w1=13.525120005589821\n",
      "SubGD iter. 183/499: loss=15.388550254125587, w0=73.23707999999993, w1=13.525275743280272\n",
      "SubGD iter. 184/499: loss=15.388541382962284, w0=73.23721999999994, w1=13.525174424196303\n",
      "SubGD iter. 185/499: loss=15.388528823582112, w0=73.23735999999994, w1=13.525073105112334\n",
      "SubGD iter. 186/499: loss=15.388516294067493, w0=73.23749999999994, w1=13.524971786028365\n",
      "SubGD iter. 187/499: loss=15.388503794418433, w0=73.23763999999994, w1=13.524870466944396\n",
      "SubGD iter. 188/499: loss=15.388491324634929, w0=73.23777999999994, w1=13.524769147860427\n",
      "SubGD iter. 189/499: loss=15.388478884716978, w0=73.23805999999995, w1=13.524924885550877\n",
      "SubGD iter. 190/499: loss=15.388470233311907, w0=73.23819999999995, w1=13.524823566466909\n",
      "SubGD iter. 191/499: loss=15.38845784668031, w0=73.23833999999995, w1=13.52472224738294\n",
      "SubGD iter. 192/499: loss=15.388445489914274, w0=73.23847999999995, w1=13.52462092829897\n",
      "SubGD iter. 193/499: loss=15.3884331630138, w0=73.23847999999995, w1=13.524586781150415\n",
      "SubGD iter. 194/499: loss=15.388431630099827, w0=73.23847999999995, w1=13.524552634001859\n",
      "SubGD iter. 195/499: loss=15.388430098351877, w0=73.23847999999995, w1=13.524518486853303\n",
      "SubGD iter. 196/499: loss=15.388428567769951, w0=73.23847999999995, w1=13.524484339704747\n",
      "SubGD iter. 197/499: loss=15.388427038354058, w0=73.23847999999995, w1=13.524450192556191\n",
      "SubGD iter. 198/499: loss=15.388425510104184, w0=73.23847999999995, w1=13.524416045407635\n",
      "SubGD iter. 199/499: loss=15.388423983020347, w0=73.23847999999995, w1=13.52438189825908\n",
      "SubGD iter. 200/499: loss=15.388422457102536, w0=73.23861999999995, w1=13.524604807884943\n",
      "SubGD iter. 201/499: loss=15.388424687119937, w0=73.23861999999995, w1=13.524570660736387\n",
      "SubGD iter. 202/499: loss=15.388423154756428, w0=73.23861999999995, w1=13.524536513587831\n",
      "SubGD iter. 203/499: loss=15.388421623558935, w0=73.23861999999995, w1=13.524502366439275\n",
      "SubGD iter. 204/499: loss=15.388420093527483, w0=73.23861999999995, w1=13.52446821929072\n",
      "SubGD iter. 205/499: loss=15.388418564662052, w0=73.23861999999995, w1=13.524434072142164\n",
      "SubGD iter. 206/499: loss=15.388417036962652, w0=73.23861999999995, w1=13.524399924993608\n",
      "SubGD iter. 207/499: loss=15.38841551042928, w0=73.23861999999995, w1=13.524365777845052\n",
      "SubGD iter. 208/499: loss=15.38841398506193, w0=73.23861999999995, w1=13.524331630696496\n",
      "SubGD iter. 209/499: loss=15.388412460860613, w0=73.23861999999995, w1=13.52429748354794\n",
      "SubGD iter. 210/499: loss=15.388410937825325, w0=73.23875999999996, w1=13.524520393173804\n",
      "SubGD iter. 211/499: loss=15.388413168625878, w0=73.23875999999996, w1=13.524486246025248\n",
      "SubGD iter. 212/499: loss=15.388411639144882, w0=73.23875999999996, w1=13.524452098876692\n",
      "SubGD iter. 213/499: loss=15.388410110829922, w0=73.23875999999996, w1=13.524417951728136\n",
      "SubGD iter. 214/499: loss=15.388408583680988, w0=73.23875999999996, w1=13.52438380457958\n",
      "SubGD iter. 215/499: loss=15.388407057698076, w0=73.23875999999996, w1=13.524349657431024\n",
      "SubGD iter. 216/499: loss=15.388405532881192, w0=73.23875999999996, w1=13.524315510282468\n",
      "SubGD iter. 217/499: loss=15.388404009230348, w0=73.23875999999996, w1=13.524281363133912\n",
      "SubGD iter. 218/499: loss=15.388402486745518, w0=73.23875999999996, w1=13.524247215985357\n",
      "SubGD iter. 219/499: loss=15.388400965426722, w0=73.23875999999996, w1=13.5242130688368\n",
      "SubGD iter. 220/499: loss=15.38839944527396, w0=73.23889999999996, w1=13.524435978462664\n",
      "SubGD iter. 221/499: loss=15.388401676857645, w0=73.23889999999996, w1=13.524401831314108\n",
      "SubGD iter. 222/499: loss=15.388400150259185, w0=73.23889999999996, w1=13.524367684165552\n",
      "SubGD iter. 223/499: loss=15.38839862482674, w0=73.23889999999996, w1=13.524333537016997\n",
      "SubGD iter. 224/499: loss=15.38839710056033, w0=73.23889999999996, w1=13.52429938986844\n",
      "SubGD iter. 225/499: loss=15.38839557745994, w0=73.23889999999996, w1=13.524265242719885\n",
      "SubGD iter. 226/499: loss=15.38839405552559, w0=73.23889999999996, w1=13.524231095571329\n",
      "SubGD iter. 227/499: loss=15.388392534757255, w0=73.23889999999996, w1=13.524196948422773\n",
      "SubGD iter. 228/499: loss=15.388391015154955, w0=73.23889999999996, w1=13.524162801274217\n",
      "SubGD iter. 229/499: loss=15.388389496718673, w0=73.23903999999996, w1=13.52438571090008\n",
      "SubGD iter. 230/499: loss=15.388391736697248, w0=73.23903999999996, w1=13.524351563751525\n",
      "SubGD iter. 231/499: loss=15.388390211815276, w0=73.23903999999996, w1=13.524317416602969\n",
      "SubGD iter. 232/499: loss=15.388388688099326, w0=73.23903999999996, w1=13.524283269454413\n",
      "SubGD iter. 233/499: loss=15.388387165549409, w0=73.23903999999996, w1=13.524249122305857\n",
      "SubGD iter. 234/499: loss=15.38838564416552, w0=73.23903999999996, w1=13.524214975157301\n",
      "SubGD iter. 235/499: loss=15.388384123947652, w0=73.23903999999996, w1=13.524180828008745\n",
      "SubGD iter. 236/499: loss=15.388382604895817, w0=73.23903999999996, w1=13.52414668086019\n",
      "SubGD iter. 237/499: loss=15.388381087010007, w0=73.23903999999996, w1=13.524112533711634\n",
      "SubGD iter. 238/499: loss=15.388379570290223, w0=73.23903999999996, w1=13.524078386563078\n",
      "SubGD iter. 239/499: loss=15.388378054736467, w0=73.23917999999996, w1=13.524301296188941\n",
      "SubGD iter. 240/499: loss=15.388380295498198, w0=73.23917999999996, w1=13.524267149040385\n",
      "SubGD iter. 241/499: loss=15.388378773498745, w0=73.23917999999996, w1=13.52423300189183\n",
      "SubGD iter. 242/499: loss=15.38837725266532, w0=73.23917999999996, w1=13.524198854743274\n",
      "SubGD iter. 243/499: loss=15.388375732997915, w0=73.23917999999996, w1=13.524164707594718\n",
      "SubGD iter. 244/499: loss=15.388374214496546, w0=73.23917999999996, w1=13.524130560446162\n",
      "SubGD iter. 245/499: loss=15.388372697161207, w0=73.23917999999996, w1=13.524096413297606\n",
      "SubGD iter. 246/499: loss=15.388371180991893, w0=73.23917999999996, w1=13.52406226614905\n",
      "SubGD iter. 247/499: loss=15.388369665988604, w0=73.23917999999996, w1=13.524028119000494\n",
      "SubGD iter. 248/499: loss=15.38836815215135, w0=73.23917999999996, w1=13.523993971851938\n",
      "SubGD iter. 249/499: loss=15.388366639480111, w0=73.23931999999996, w1=13.524216881477802\n",
      "SubGD iter. 250/499: loss=15.388368881024984, w0=73.23931999999996, w1=13.524182734329246\n",
      "SubGD iter. 251/499: loss=15.388367361908056, w0=73.23931999999996, w1=13.52414858718069\n",
      "SubGD iter. 252/499: loss=15.388365843957148, w0=73.23931999999996, w1=13.524114440032134\n",
      "SubGD iter. 253/499: loss=15.38836432717227, w0=73.23931999999996, w1=13.524080292883578\n",
      "SubGD iter. 254/499: loss=15.388362811553426, w0=73.23931999999996, w1=13.524046145735023\n",
      "SubGD iter. 255/499: loss=15.388361297100607, w0=73.23931999999996, w1=13.524011998586467\n",
      "SubGD iter. 256/499: loss=15.388359783813808, w0=73.23931999999996, w1=13.52397785143791\n",
      "SubGD iter. 257/499: loss=15.388358271693045, w0=73.23931999999996, w1=13.523943704289355\n",
      "SubGD iter. 258/499: loss=15.388356760738313, w0=73.23931999999996, w1=13.523909557140799\n",
      "SubGD iter. 259/499: loss=15.388355250949596, w0=73.23945999999997, w1=13.524132466766662\n",
      "SubGD iter. 260/499: loss=15.388357493277622, w0=73.23945999999997, w1=13.524098319618107\n",
      "SubGD iter. 261/499: loss=15.388355977043206, w0=73.23945999999997, w1=13.52406417246955\n",
      "SubGD iter. 262/499: loss=15.388354461974826, w0=73.23945999999997, w1=13.524030025320995\n",
      "SubGD iter. 263/499: loss=15.388352948072466, w0=73.23945999999997, w1=13.523995878172439\n",
      "SubGD iter. 264/499: loss=15.388351435336142, w0=73.23945999999997, w1=13.523961731023883\n",
      "SubGD iter. 265/499: loss=15.388349923765846, w0=73.23945999999997, w1=13.523927583875327\n",
      "SubGD iter. 266/499: loss=15.388348413361575, w0=73.23945999999997, w1=13.523893436726771\n",
      "SubGD iter. 267/499: loss=15.38834690412333, w0=73.23945999999997, w1=13.523859289578215\n",
      "SubGD iter. 268/499: loss=15.388345396051117, w0=73.23959999999997, w1=13.524082199204079\n",
      "SubGD iter. 269/499: loss=15.388347646774005, w0=73.23959999999997, w1=13.524048052055523\n",
      "SubGD iter. 270/499: loss=15.388346132256096, w0=73.23959999999997, w1=13.524013904906967\n",
      "SubGD iter. 271/499: loss=15.3883446189042, w0=73.23959999999997, w1=13.523979757758411\n",
      "SubGD iter. 272/499: loss=15.388343106718338, w0=73.23959999999997, w1=13.523945610609855\n",
      "SubGD iter. 273/499: loss=15.38834159569851, w0=73.23959999999997, w1=13.5239114634613\n",
      "SubGD iter. 274/499: loss=15.388340085844701, w0=73.23959999999997, w1=13.523877316312744\n",
      "SubGD iter. 275/499: loss=15.38833857715693, w0=73.23959999999997, w1=13.523843169164188\n",
      "SubGD iter. 276/499: loss=15.388337069635181, w0=73.23959999999997, w1=13.523809022015632\n",
      "SubGD iter. 277/499: loss=15.388335563279458, w0=73.23959999999997, w1=13.523774874867076\n",
      "SubGD iter. 278/499: loss=15.388334058089757, w0=73.23973999999997, w1=13.52399778449294\n",
      "SubGD iter. 279/499: loss=15.388336309595804, w0=73.23973999999997, w1=13.523963637344384\n",
      "SubGD iter. 280/499: loss=15.388334797960413, w0=73.23973999999997, w1=13.523929490195828\n",
      "SubGD iter. 281/499: loss=15.388333287491044, w0=73.23973999999997, w1=13.523895343047272\n",
      "SubGD iter. 282/499: loss=15.3883317781877, w0=73.23973999999997, w1=13.523861195898716\n",
      "SubGD iter. 283/499: loss=15.388330270050393, w0=73.23973999999997, w1=13.52382704875016\n",
      "SubGD iter. 284/499: loss=15.388328763079114, w0=73.23973999999997, w1=13.523792901601604\n",
      "SubGD iter. 285/499: loss=15.388327257273852, w0=73.23973999999997, w1=13.523758754453048\n",
      "SubGD iter. 286/499: loss=15.38832575263463, w0=73.23973999999997, w1=13.523724607304493\n",
      "SubGD iter. 287/499: loss=15.388324249161425, w0=73.23973999999997, w1=13.523690460155937\n",
      "SubGD iter. 288/499: loss=15.388322746854252, w0=73.23987999999997, w1=13.5239133697818\n",
      "SubGD iter. 289/499: loss=15.388324999143444, w0=73.23987999999997, w1=13.523879222633244\n",
      "SubGD iter. 290/499: loss=15.388323490390578, w0=73.23987999999997, w1=13.523845075484688\n",
      "SubGD iter. 291/499: loss=15.388321982803726, w0=73.23987999999997, w1=13.523810928336133\n",
      "SubGD iter. 292/499: loss=15.388320476382907, w0=73.23987999999997, w1=13.523776781187577\n",
      "SubGD iter. 293/499: loss=15.388318971128118, w0=73.23987999999997, w1=13.52374263403902\n",
      "SubGD iter. 294/499: loss=15.388317467039364, w0=73.23987999999997, w1=13.523708486890465\n",
      "SubGD iter. 295/499: loss=15.388315964116622, w0=73.23987999999997, w1=13.523674339741909\n",
      "SubGD iter. 296/499: loss=15.388314462359919, w0=73.23987999999997, w1=13.523640192593353\n",
      "SubGD iter. 297/499: loss=15.388312961769238, w0=73.23987999999997, w1=13.523606045444797\n",
      "SubGD iter. 298/499: loss=15.388311462344596, w0=73.24001999999997, w1=13.52382895507066\n",
      "SubGD iter. 299/499: loss=15.388313715416926, w0=73.24001999999997, w1=13.523794807922105\n",
      "SubGD iter. 300/499: loss=15.388312209546584, w0=73.24001999999997, w1=13.523760660773549\n",
      "SubGD iter. 301/499: loss=15.388310704842253, w0=73.24001999999997, w1=13.523726513624993\n",
      "SubGD iter. 302/499: loss=15.388309201303963, w0=73.24001999999997, w1=13.523692366476437\n",
      "SubGD iter. 303/499: loss=15.388307698931685, w0=73.24001999999997, w1=13.523658219327881\n",
      "SubGD iter. 304/499: loss=15.388306197725454, w0=73.24001999999997, w1=13.523624072179325\n",
      "SubGD iter. 305/499: loss=15.388304697685241, w0=73.24001999999997, w1=13.52358992503077\n",
      "SubGD iter. 306/499: loss=15.388303198811053, w0=73.24001999999997, w1=13.523555777882214\n",
      "SubGD iter. 307/499: loss=15.3883017011029, w0=73.24015999999997, w1=13.523778687508077\n",
      "SubGD iter. 308/499: loss=15.388303962570111, w0=73.24015999999997, w1=13.523744540359521\n",
      "SubGD iter. 309/499: loss=15.388302458416257, w0=73.24015999999997, w1=13.523710393210965\n",
      "SubGD iter. 310/499: loss=15.38830095542843, w0=73.24015999999997, w1=13.52367624606241\n",
      "SubGD iter. 311/499: loss=15.388299453606626, w0=73.24015999999997, w1=13.523642098913854\n",
      "SubGD iter. 312/499: loss=15.38829795295085, w0=73.24015999999997, w1=13.523607951765298\n",
      "SubGD iter. 313/499: loss=15.388296453461109, w0=73.24015999999997, w1=13.523573804616742\n",
      "SubGD iter. 314/499: loss=15.38829495513739, w0=73.24015999999997, w1=13.523539657468186\n",
      "SubGD iter. 315/499: loss=15.388293457979694, w0=73.24015999999997, w1=13.52350551031963\n",
      "SubGD iter. 316/499: loss=15.388291961988033, w0=73.24015999999997, w1=13.523471363171074\n",
      "SubGD iter. 317/499: loss=15.388290467162395, w0=73.24029999999998, w1=13.523694272796938\n",
      "SubGD iter. 318/499: loss=15.388292729412766, w0=73.24029999999998, w1=13.523660125648382\n",
      "SubGD iter. 319/499: loss=15.388291228141428, w0=73.24029999999998, w1=13.523625978499826\n",
      "SubGD iter. 320/499: loss=15.38828972803612, w0=73.24029999999998, w1=13.52359183135127\n",
      "SubGD iter. 321/499: loss=15.388288229096844, w0=73.24029999999998, w1=13.523557684202714\n",
      "SubGD iter. 322/499: loss=15.388286731323587, w0=73.24029999999998, w1=13.523523537054158\n",
      "SubGD iter. 323/499: loss=15.38828523471636, w0=73.24029999999998, w1=13.523489389905603\n",
      "SubGD iter. 324/499: loss=15.388283739275165, w0=73.24029999999998, w1=13.523455242757047\n",
      "SubGD iter. 325/499: loss=15.388282245000001, w0=73.24029999999998, w1=13.52342109560849\n",
      "SubGD iter. 326/499: loss=15.388280751890857, w0=73.24029999999998, w1=13.523386948459935\n",
      "SubGD iter. 327/499: loss=15.388279259947746, w0=73.24043999999998, w1=13.523609858085798\n",
      "SubGD iter. 328/499: loss=15.388281522981258, w0=73.24043999999998, w1=13.523575710937243\n",
      "SubGD iter. 329/499: loss=15.388280024592445, w0=73.24043999999998, w1=13.523541563788687\n",
      "SubGD iter. 330/499: loss=15.388278527369655, w0=73.24043999999998, w1=13.52350741664013\n",
      "SubGD iter. 331/499: loss=15.388277031312901, w0=73.24043999999998, w1=13.523473269491575\n",
      "SubGD iter. 332/499: loss=15.388275536422169, w0=73.24043999999998, w1=13.523439122343019\n",
      "SubGD iter. 333/499: loss=15.38827404269747, w0=73.24043999999998, w1=13.523404975194463\n",
      "SubGD iter. 334/499: loss=15.38827255013879, w0=73.24043999999998, w1=13.523370828045907\n",
      "SubGD iter. 335/499: loss=15.388271058746145, w0=73.24043999999998, w1=13.523336680897351\n",
      "SubGD iter. 336/499: loss=15.388269568519528, w0=73.24043999999998, w1=13.523302533748796\n",
      "SubGD iter. 337/499: loss=15.388268079458928, w0=73.24057999999998, w1=13.523525443374659\n",
      "SubGD iter. 338/499: loss=15.388270343275593, w0=73.24057999999998, w1=13.523491296226103\n",
      "SubGD iter. 339/499: loss=15.3882688477693, w0=73.24057999999998, w1=13.523457149077547\n",
      "SubGD iter. 340/499: loss=15.388267353429043, w0=73.24057999999998, w1=13.523423001928991\n",
      "SubGD iter. 341/499: loss=15.38826586025481, w0=73.24057999999998, w1=13.523388854780436\n",
      "SubGD iter. 342/499: loss=15.388264368246595, w0=73.24057999999998, w1=13.52335470763188\n",
      "SubGD iter. 343/499: loss=15.38826287740441, w0=73.24057999999998, w1=13.523320560483324\n",
      "SubGD iter. 344/499: loss=15.38826138772826, w0=73.24057999999998, w1=13.523286413334768\n",
      "SubGD iter. 345/499: loss=15.38825989921813, w0=73.24057999999998, w1=13.523252266186212\n",
      "SubGD iter. 346/499: loss=15.38825841187403, w0=73.24057999999998, w1=13.523218119037656\n",
      "SubGD iter. 347/499: loss=15.388256925695966, w0=73.24071999999998, w1=13.52344102866352\n",
      "SubGD iter. 348/499: loss=15.388259190295773, w0=73.24071999999998, w1=13.523406881514964\n",
      "SubGD iter. 349/499: loss=15.388257697672007, w0=73.24071999999998, w1=13.523372734366408\n",
      "SubGD iter. 350/499: loss=15.388256206214262, w0=73.24071999999998, w1=13.523338587217852\n",
      "SubGD iter. 351/499: loss=15.388254715922539, w0=73.24071999999998, w1=13.523304440069296\n",
      "SubGD iter. 352/499: loss=15.388253226796861, w0=73.24071999999998, w1=13.52327029292074\n",
      "SubGD iter. 353/499: loss=15.388251738837202, w0=73.24071999999998, w1=13.523236145772184\n",
      "SubGD iter. 354/499: loss=15.38825025204356, w0=73.24071999999998, w1=13.523201998623628\n",
      "SubGD iter. 355/499: loss=15.388248766415963, w0=73.24071999999998, w1=13.523167851475073\n",
      "SubGD iter. 356/499: loss=15.38824728195439, w0=73.24085999999998, w1=13.523390761100936\n",
      "SubGD iter. 357/499: loss=15.388249554949079, w0=73.24085999999998, w1=13.52335661395238\n",
      "SubGD iter. 358/499: loss=15.388248064041798, w0=73.24085999999998, w1=13.523322466803824\n",
      "SubGD iter. 359/499: loss=15.388246574300556, w0=73.24085999999998, w1=13.523288319655268\n",
      "SubGD iter. 360/499: loss=15.38824508572533, w0=73.24085999999998, w1=13.523254172506713\n",
      "SubGD iter. 361/499: loss=15.388243598316144, w0=73.24085999999998, w1=13.523220025358157\n",
      "SubGD iter. 362/499: loss=15.388242112072964, w0=73.24085999999998, w1=13.5231858782096\n",
      "SubGD iter. 363/499: loss=15.388240626995836, w0=73.24085999999998, w1=13.523151731061045\n",
      "SubGD iter. 364/499: loss=15.38823914308472, w0=73.24085999999998, w1=13.523117583912489\n",
      "SubGD iter. 365/499: loss=15.388237660339643, w0=73.24085999999998, w1=13.523083436763933\n",
      "SubGD iter. 366/499: loss=15.388236178760586, w0=73.24099999999999, w1=13.523306346389797\n",
      "SubGD iter. 367/499: loss=15.388238452538422, w0=73.24099999999999, w1=13.52327219924124\n",
      "SubGD iter. 368/499: loss=15.38823696451366, w0=73.24099999999999, w1=13.523238052092685\n",
      "SubGD iter. 369/499: loss=15.388235477654932, w0=73.24099999999999, w1=13.523203904944129\n",
      "SubGD iter. 370/499: loss=15.38823399196224, w0=73.24099999999999, w1=13.523169757795573\n",
      "SubGD iter. 371/499: loss=15.388232507435568, w0=73.24099999999999, w1=13.523135610647017\n",
      "SubGD iter. 372/499: loss=15.388231024074924, w0=73.24099999999999, w1=13.523101463498461\n",
      "SubGD iter. 373/499: loss=15.388229541880312, w0=73.24099999999999, w1=13.523067316349906\n",
      "SubGD iter. 374/499: loss=15.388228060851718, w0=73.24099999999999, w1=13.52303316920135\n",
      "SubGD iter. 375/499: loss=15.388226580989155, w0=73.24099999999999, w1=13.522999022052794\n",
      "SubGD iter. 376/499: loss=15.388225102292626, w0=73.24113999999999, w1=13.523221931678657\n",
      "SubGD iter. 377/499: loss=15.388227376853614, w0=73.24113999999999, w1=13.523187784530101\n",
      "SubGD iter. 378/499: loss=15.388225891711377, w0=73.24113999999999, w1=13.523153637381546\n",
      "SubGD iter. 379/499: loss=15.38822440773517, w0=73.24113999999999, w1=13.52311949023299\n",
      "SubGD iter. 380/499: loss=15.388222924924994, w0=73.24113999999999, w1=13.523085343084434\n",
      "SubGD iter. 381/499: loss=15.38822144328084, w0=73.24113999999999, w1=13.523051195935878\n",
      "SubGD iter. 382/499: loss=15.388219962802719, w0=73.24113999999999, w1=13.523017048787322\n",
      "SubGD iter. 383/499: loss=15.38821848349063, w0=73.24113999999999, w1=13.522982901638766\n",
      "SubGD iter. 384/499: loss=15.38821700534456, w0=73.24113999999999, w1=13.52294875449021\n",
      "SubGD iter. 385/499: loss=15.388215528364523, w0=73.24113999999999, w1=13.522914607341654\n",
      "SubGD iter. 386/499: loss=15.38821405255051, w0=73.24127999999999, w1=13.523137516967518\n",
      "SubGD iter. 387/499: loss=15.388216327894636, w0=73.24127999999999, w1=13.523103369818962\n",
      "SubGD iter. 388/499: loss=15.388214845634927, w0=73.24127999999999, w1=13.523069222670406\n",
      "SubGD iter. 389/499: loss=15.388213364541246, w0=73.24127999999999, w1=13.52303507552185\n",
      "SubGD iter. 390/499: loss=15.388211884613591, w0=73.24127999999999, w1=13.523000928373294\n",
      "SubGD iter. 391/499: loss=15.388210405851959, w0=73.24127999999999, w1=13.522966781224738\n",
      "SubGD iter. 392/499: loss=15.38820892825636, w0=73.24127999999999, w1=13.522932634076183\n",
      "SubGD iter. 393/499: loss=15.38820745182679, w0=73.24127999999999, w1=13.522898486927627\n",
      "SubGD iter. 394/499: loss=15.388205976563247, w0=73.24127999999999, w1=13.52286433977907\n",
      "SubGD iter. 395/499: loss=15.38820450246572, w0=73.24141999999999, w1=13.523087249404934\n",
      "SubGD iter. 396/499: loss=15.388206786204735, w0=73.24141999999999, w1=13.523053102256378\n",
      "SubGD iter. 397/499: loss=15.38820530566152, w0=73.24141999999999, w1=13.523018955107823\n",
      "SubGD iter. 398/499: loss=15.388203826284323, w0=73.24141999999999, w1=13.522984807959267\n",
      "SubGD iter. 399/499: loss=15.388202348073165, w0=73.24141999999999, w1=13.52295066081071\n",
      "SubGD iter. 400/499: loss=15.388200871028026, w0=73.24141999999999, w1=13.522916513662155\n",
      "SubGD iter. 401/499: loss=15.388199395148922, w0=73.24141999999999, w1=13.522882366513599\n",
      "SubGD iter. 402/499: loss=15.388197920435845, w0=73.24141999999999, w1=13.522848219365043\n",
      "SubGD iter. 403/499: loss=15.388196446888792, w0=73.24141999999999, w1=13.522814072216487\n",
      "SubGD iter. 404/499: loss=15.388194974507769, w0=73.24141999999999, w1=13.522779925067931\n",
      "SubGD iter. 405/499: loss=15.388193503292777, w0=73.24155999999999, w1=13.523002834693795\n",
      "SubGD iter. 406/499: loss=15.388195787814931, w0=73.24155999999999, w1=13.522968687545239\n",
      "SubGD iter. 407/499: loss=15.388194310154237, w0=73.24155999999999, w1=13.522934540396683\n",
      "SubGD iter. 408/499: loss=15.388192833659563, w0=73.24155999999999, w1=13.522900393248127\n",
      "SubGD iter. 409/499: loss=15.388191358330927, w0=73.24155999999999, w1=13.522866246099571\n",
      "SubGD iter. 410/499: loss=15.38818988416831, w0=73.24155999999999, w1=13.522832098951016\n",
      "SubGD iter. 411/499: loss=15.388188411171729, w0=73.24155999999999, w1=13.52279795180246\n",
      "SubGD iter. 412/499: loss=15.388186939341168, w0=73.24155999999999, w1=13.522763804653904\n",
      "SubGD iter. 413/499: loss=15.388185468676642, w0=73.24155999999999, w1=13.522729657505348\n",
      "SubGD iter. 414/499: loss=15.388183999178139, w0=73.24155999999999, w1=13.522695510356792\n",
      "SubGD iter. 415/499: loss=15.388182530845667, w0=73.2417, w1=13.522918419982656\n",
      "SubGD iter. 416/499: loss=15.388184816150966, w0=73.24155999999999, w1=13.522905630681189\n",
      "SubGD iter. 417/499: loss=15.38819158453868, w0=73.24155999999999, w1=13.522871483532633\n",
      "SubGD iter. 418/499: loss=15.388190110197224, w0=73.24155999999999, w1=13.522837336384077\n",
      "SubGD iter. 419/499: loss=15.388188637021795, w0=73.24155999999999, w1=13.522803189235521\n",
      "SubGD iter. 420/499: loss=15.388187165012402, w0=73.24155999999999, w1=13.522769042086965\n",
      "SubGD iter. 421/499: loss=15.388185694169032, w0=73.24155999999999, w1=13.52273489493841\n",
      "SubGD iter. 422/499: loss=15.388184224491678, w0=73.24155999999999, w1=13.522700747789854\n",
      "SubGD iter. 423/499: loss=15.388182755980361, w0=73.2417, w1=13.522923657415717\n",
      "SubGD iter. 424/499: loss=15.388185042453138, w0=73.24155999999999, w1=13.52291086811425\n",
      "SubGD iter. 425/499: loss=15.388191810773872, w0=73.24155999999999, w1=13.522876720965694\n",
      "SubGD iter. 426/499: loss=15.388190336253563, w0=73.24155999999999, w1=13.522842573817139\n",
      "SubGD iter. 427/499: loss=15.388188862899304, w0=73.24155999999999, w1=13.522808426668583\n",
      "SubGD iter. 428/499: loss=15.388187390711053, w0=73.24155999999999, w1=13.522774279520027\n",
      "SubGD iter. 429/499: loss=15.38818591968884, w0=73.24155999999999, w1=13.52274013237147\n",
      "SubGD iter. 430/499: loss=15.388184449832648, w0=73.24155999999999, w1=13.522705985222915\n",
      "SubGD iter. 431/499: loss=15.388182981142487, w0=73.2417, w1=13.522928894848778\n",
      "SubGD iter. 432/499: loss=15.388185268782737, w0=73.24155999999999, w1=13.522916105547312\n",
      "SubGD iter. 433/499: loss=15.388192037036491, w0=73.24155999999999, w1=13.522881958398756\n",
      "SubGD iter. 434/499: loss=15.388190562337337, w0=73.24155999999999, w1=13.5228478112502\n",
      "SubGD iter. 435/499: loss=15.388189088804229, w0=73.24155999999999, w1=13.522813664101644\n",
      "SubGD iter. 436/499: loss=15.388187616437142, w0=73.24155999999999, w1=13.522779516953088\n",
      "SubGD iter. 437/499: loss=15.388186145236082, w0=73.24155999999999, w1=13.522745369804532\n",
      "SubGD iter. 438/499: loss=15.388184675201051, w0=73.24155999999999, w1=13.522711222655976\n",
      "SubGD iter. 439/499: loss=15.388183206332046, w0=73.2417, w1=13.52293413228184\n",
      "SubGD iter. 440/499: loss=15.38818549513977, w0=73.24155999999999, w1=13.522921342980373\n",
      "SubGD iter. 441/499: loss=15.388192263326532, w0=73.24155999999999, w1=13.522887195831817\n",
      "SubGD iter. 442/499: loss=15.388190788448549, w0=73.24155999999999, w1=13.522853048683261\n",
      "SubGD iter. 443/499: loss=15.388189314736586, w0=73.24155999999999, w1=13.522818901534706\n",
      "SubGD iter. 444/499: loss=15.388187842190655, w0=73.24155999999999, w1=13.52278475438615\n",
      "SubGD iter. 445/499: loss=15.388186370810761, w0=73.24155999999999, w1=13.522750607237594\n",
      "SubGD iter. 446/499: loss=15.388184900596883, w0=73.24155999999999, w1=13.522716460089038\n",
      "SubGD iter. 447/499: loss=15.38818343154903, w0=73.2417, w1=13.522939369714901\n",
      "SubGD iter. 448/499: loss=15.388185721524234, w0=73.24155999999999, w1=13.522926580413435\n",
      "SubGD iter. 449/499: loss=15.388192489644013, w0=73.24155999999999, w1=13.522892433264879\n",
      "SubGD iter. 450/499: loss=15.38819101458718, w0=73.24155999999999, w1=13.522858286116323\n",
      "SubGD iter. 451/499: loss=15.388189540696382, w0=73.24155999999999, w1=13.522824138967767\n",
      "SubGD iter. 452/499: loss=15.388188067971607, w0=73.24155999999999, w1=13.522789991819211\n",
      "SubGD iter. 453/499: loss=15.388186596412861, w0=73.24155999999999, w1=13.522755844670655\n",
      "SubGD iter. 454/499: loss=15.388185126020142, w0=73.24155999999999, w1=13.5227216975221\n",
      "SubGD iter. 455/499: loss=15.388183656793448, w0=73.24155999999999, w1=13.522687550373544\n",
      "SubGD iter. 456/499: loss=15.388182188732785, w0=73.2417, w1=13.522910459999407\n",
      "SubGD iter. 457/499: loss=15.388184472263733, w0=73.24155999999999, w1=13.52289767069794\n",
      "SubGD iter. 458/499: loss=15.388191240753248, w0=73.24155999999999, w1=13.522863523549384\n",
      "SubGD iter. 459/499: loss=15.388189766683599, w0=73.24155999999999, w1=13.522829376400828\n",
      "SubGD iter. 460/499: loss=15.38818829377998, w0=73.24155999999999, w1=13.522795229252273\n",
      "SubGD iter. 461/499: loss=15.3881868220424, w0=73.24155999999999, w1=13.522761082103717\n",
      "SubGD iter. 462/499: loss=15.38818535147083, w0=73.24155999999999, w1=13.52272693495516\n",
      "SubGD iter. 463/499: loss=15.388183882065297, w0=73.24155999999999, w1=13.522692787806605\n",
      "SubGD iter. 464/499: loss=15.388182413825794, w0=73.2417, w1=13.522915697432468\n",
      "SubGD iter. 465/499: loss=15.38818469852421, w0=73.24155999999999, w1=13.522902908131002\n",
      "SubGD iter. 466/499: loss=15.388191466946749, w0=73.24155999999999, w1=13.522868760982446\n",
      "SubGD iter. 467/499: loss=15.388189992698257, w0=73.24155999999999, w1=13.52283461383389\n",
      "SubGD iter. 468/499: loss=15.388188519615799, w0=73.24155999999999, w1=13.522800466685334\n",
      "SubGD iter. 469/499: loss=15.388187047699361, w0=73.24155999999999, w1=13.522766319536778\n",
      "SubGD iter. 470/499: loss=15.388185576948954, w0=73.24155999999999, w1=13.522732172388222\n",
      "SubGD iter. 471/499: loss=15.388184107364584, w0=73.24155999999999, w1=13.522698025239666\n",
      "SubGD iter. 472/499: loss=15.388182638946233, w0=73.2417, w1=13.52292093486553\n",
      "SubGD iter. 473/499: loss=15.388184924812123, w0=73.24155999999999, w1=13.522908145564063\n",
      "SubGD iter. 474/499: loss=15.388191693167673, w0=73.24155999999999, w1=13.522873998415507\n",
      "SubGD iter. 475/499: loss=15.388190218740347, w0=73.24155999999999, w1=13.522839851266951\n",
      "SubGD iter. 476/499: loss=15.388188745479038, w0=73.24155999999999, w1=13.522805704118396\n",
      "SubGD iter. 477/499: loss=15.388187273383764, w0=73.24155999999999, w1=13.52277155696984\n",
      "SubGD iter. 478/499: loss=15.38818580245451, w0=73.24155999999999, w1=13.522737409821284\n",
      "SubGD iter. 479/499: loss=15.38818433269129, w0=73.24155999999999, w1=13.522703262672728\n",
      "SubGD iter. 480/499: loss=15.388182864094095, w0=73.2417, w1=13.522926172298591\n",
      "SubGD iter. 481/499: loss=15.388185151127464, w0=73.24155999999999, w1=13.522913382997125\n",
      "SubGD iter. 482/499: loss=15.388191919416027, w0=73.24155999999999, w1=13.522879235848569\n",
      "SubGD iter. 483/499: loss=15.388190444809856, w0=73.24155999999999, w1=13.522845088700013\n",
      "SubGD iter. 484/499: loss=15.388188971369711, w0=73.24155999999999, w1=13.522810941551457\n",
      "SubGD iter. 485/499: loss=15.38818749909559, w0=73.24155999999999, w1=13.522776794402901\n",
      "SubGD iter. 486/499: loss=15.388186027987494, w0=73.24155999999999, w1=13.522742647254345\n",
      "SubGD iter. 487/499: loss=15.388184558045433, w0=73.24155999999999, w1=13.52270850010579\n",
      "SubGD iter. 488/499: loss=15.388183089269395, w0=73.2417, w1=13.522931409731653\n",
      "SubGD iter. 489/499: loss=15.388185377470242, w0=73.24155999999999, w1=13.522918620430186\n",
      "SubGD iter. 490/499: loss=15.388192145691818, w0=73.24155999999999, w1=13.52288447328163\n",
      "SubGD iter. 491/499: loss=15.388190670906798, w0=73.24155999999999, w1=13.522850326133074\n",
      "SubGD iter. 492/499: loss=15.388189197287813, w0=73.24155999999999, w1=13.522816178984518\n",
      "SubGD iter. 493/499: loss=15.388187724834847, w0=73.24155999999999, w1=13.522782031835963\n",
      "SubGD iter. 494/499: loss=15.38818625354791, w0=73.24155999999999, w1=13.522747884687407\n",
      "SubGD iter. 495/499: loss=15.388184783426999, w0=73.24155999999999, w1=13.52271373753885\n",
      "SubGD iter. 496/499: loss=15.388183314472123, w0=73.2417, w1=13.522936647164714\n",
      "SubGD iter. 497/499: loss=15.388185603840443, w0=73.24155999999999, w1=13.522923857863248\n",
      "SubGD iter. 498/499: loss=15.388192371995038, w0=73.24155999999999, w1=13.522889710714692\n",
      "SubGD iter. 499/499: loss=15.388190897031182, w0=73.24155999999999, w1=13.522855563566136\n",
      "SubGD: execution time=0.081 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155cacfc1e9c49409078c0125cec8478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "\n",
    "            subgradient = compute_subgradient_mae(minibatch_y, minibatch_tx, w)\n",
    "\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        \n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "\n",
    "        w = w - gamma * subgradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=2792.236712759168, w0=0.7, w1=-1.2842258424216995\n",
      "SubSGD iter. 1/499: loss=2759.3115804222916, w0=1.4, w1=0.04908366223897809\n",
      "SubSGD iter. 2/499: loss=2689.944792906932, w0=2.0999999999999996, w1=0.9073583446448136\n",
      "SubSGD iter. 3/499: loss=2628.7051965762453, w0=2.8, w1=-0.520117923370717\n",
      "SubSGD iter. 4/499: loss=2598.0800325196997, w0=3.5, w1=-0.5974262712594278\n",
      "SubSGD iter. 5/499: loss=2550.0645791642787, w0=4.2, w1=-0.9937758948288291\n",
      "SubSGD iter. 6/499: loss=2507.1118489020123, w0=4.9, w1=-1.3656725205857922\n",
      "SubSGD iter. 7/499: loss=2464.442898523456, w0=5.6000000000000005, w1=-0.9121763818612685\n",
      "SubSGD iter. 8/499: loss=2410.182657740669, w0=6.300000000000001, w1=-0.4498396588591401\n",
      "SubSGD iter. 9/499: loss=2356.4948912485206, w0=7.000000000000001, w1=0.4588810542240378\n",
      "SubSGD iter. 10/499: loss=2297.5989600025887, w0=7.700000000000001, w1=-0.12659810923137416\n",
      "SubSGD iter. 11/499: loss=2259.2330329908395, w0=8.4, w1=0.42190611893116925\n",
      "SubSGD iter. 12/499: loss=2206.249597170325, w0=9.1, w1=-0.29922901745707453\n",
      "SubSGD iter. 13/499: loss=2170.7453126499804, w0=9.799999999999999, w1=-1.103133845892864\n",
      "SubSGD iter. 14/499: loss=2137.4546562994524, w0=10.499999999999998, w1=-0.8017907847189636\n",
      "SubSGD iter. 15/499: loss=2088.9048751793284, w0=11.199999999999998, w1=-1.182693505790675\n",
      "SubSGD iter. 16/499: loss=2050.7065366566962, w0=11.899999999999997, w1=-1.5737358302563762\n",
      "SubSGD iter. 17/499: loss=2013.2958696063272, w0=12.599999999999996, w1=-1.701444241824092\n",
      "SubSGD iter. 18/499: loss=1972.4957308906178, w0=13.299999999999995, w1=-2.1128887567719796\n",
      "SubSGD iter. 19/499: loss=1936.5858324288222, w0=13.999999999999995, w1=-2.439159248279924\n",
      "SubSGD iter. 20/499: loss=1899.9757188988865, w0=14.699999999999994, w1=-2.475516504532662\n",
      "SubSGD iter. 21/499: loss=1859.2944009194973, w0=15.399999999999993, w1=-1.4247652025798725\n",
      "SubSGD iter. 22/499: loss=1802.3107170861442, w0=16.099999999999994, w1=-0.6984205961067799\n",
      "SubSGD iter. 23/499: loss=1751.4679729840002, w0=16.799999999999994, w1=-0.7716954482918313\n",
      "SubSGD iter. 24/499: loss=1712.7188127866211, w0=17.499999999999993, w1=-0.26001447264978605\n",
      "SubSGD iter. 25/499: loss=1666.2568018055752, w0=18.199999999999992, w1=-0.9221208339283596\n",
      "SubSGD iter. 26/499: loss=1636.762409408702, w0=18.89999999999999, w1=-1.5022883190054344\n",
      "SubSGD iter. 27/499: loss=1606.9654365507263, w0=19.59999999999999, w1=-2.165390010336504\n",
      "SubSGD iter. 28/499: loss=1579.2891331152732, w0=20.29999999999999, w1=-2.670832752350413\n",
      "SubSGD iter. 29/499: loss=1549.9838273755804, w0=20.99999999999999, w1=-3.09513795166697\n",
      "SubSGD iter. 30/499: loss=1520.0758597199754, w0=21.69999999999999, w1=-3.6150265845425653\n",
      "SubSGD iter. 31/499: loss=1492.4673327214346, w0=22.399999999999988, w1=-4.4339567973475535\n",
      "SubSGD iter. 32/499: loss=1470.9313089297934, w0=23.099999999999987, w1=-5.424782260736897\n",
      "SubSGD iter. 33/499: loss=1453.790750695904, w0=23.799999999999986, w1=-6.288038473308868\n",
      "SubSGD iter. 34/499: loss=1435.5920334303214, w0=24.499999999999986, w1=-5.703822247696634\n",
      "SubSGD iter. 35/499: loss=1389.813301503494, w0=25.199999999999985, w1=-5.735441937908077\n",
      "SubSGD iter. 36/499: loss=1356.509633428252, w0=25.899999999999984, w1=-7.008945144791537\n",
      "SubSGD iter. 37/499: loss=1348.3703539503947, w0=26.599999999999984, w1=-6.501426234468235\n",
      "SubSGD iter. 38/499: loss=1305.1700151022117, w0=27.299999999999983, w1=-6.672749930315932\n",
      "SubSGD iter. 39/499: loss=1276.1671881292139, w0=27.999999999999982, w1=-7.397343997868319\n",
      "SubSGD iter. 40/499: loss=1259.0813156855793, w0=28.69999999999998, w1=-6.912596586871376\n",
      "SubSGD iter. 41/499: loss=1217.6179612552746, w0=29.39999999999998, w1=-6.782236631552757\n",
      "SubSGD iter. 42/499: loss=1183.9973722198433, w0=30.09999999999998, w1=-6.48175261753663\n",
      "SubSGD iter. 43/499: loss=1147.4733803524043, w0=30.79999999999998, w1=-5.849516041007638\n",
      "SubSGD iter. 44/499: loss=1105.0621281679694, w0=31.49999999999998, w1=-6.856271161874441\n",
      "SubSGD iter. 45/499: loss=1095.5279604538057, w0=32.19999999999998, w1=-6.164225736066407\n",
      "SubSGD iter. 46/499: loss=1052.6832540605064, w0=32.899999999999984, w1=-7.186141009078373\n",
      "SubSGD iter. 47/499: loss=1044.7591045107447, w0=33.59999999999999, w1=-7.837651333463793\n",
      "SubSGD iter. 48/499: loss=1030.4046088417065, w0=34.29999999999999, w1=-7.916456572073311\n",
      "SubSGD iter. 49/499: loss=1004.5468885113485, w0=34.99999999999999, w1=-8.903587000316415\n",
      "SubSGD iter. 50/499: loss=999.1041658257592, w0=35.699999999999996, w1=-8.730154894259156\n",
      "SubSGD iter. 51/499: loss=968.6764770104162, w0=36.4, w1=-8.619331265855761\n",
      "SubSGD iter. 52/499: loss=940.1504944634634, w0=37.1, w1=-7.854821243236868\n",
      "SubSGD iter. 53/499: loss=897.9670464497432, w0=37.800000000000004, w1=-7.480815638380805\n",
      "SubSGD iter. 54/499: loss=864.967005971855, w0=38.50000000000001, w1=-6.602421861887586\n",
      "SubSGD iter. 55/499: loss=822.3404509720126, w0=39.20000000000001, w1=-6.1913508342940835\n",
      "SubSGD iter. 56/499: loss=790.0590116837142, w0=39.90000000000001, w1=-6.6189926836004345\n",
      "SubSGD iter. 57/499: loss=774.9418749321783, w0=40.600000000000016, w1=-7.7237752406051206\n",
      "SubSGD iter. 58/499: loss=774.6261006132339, w0=41.30000000000002, w1=-7.97213761259065\n",
      "SubSGD iter. 59/499: loss=757.282345639146, w0=42.00000000000002, w1=-7.924579908609552\n",
      "SubSGD iter. 60/499: loss=734.1125303708664, w0=42.700000000000024, w1=-7.4522576549868145\n",
      "SubSGD iter. 61/499: loss=702.4536055280981, w0=43.40000000000003, w1=-6.388539073956651\n",
      "SubSGD iter. 62/499: loss=659.5828832141636, w0=44.10000000000003, w1=-7.0932418516578535\n",
      "SubSGD iter. 63/499: loss=653.15165284156, w0=44.80000000000003, w1=-7.252960422875021\n",
      "SubSGD iter. 64/499: loss=636.2595453154617, w0=44.10000000000003, w1=-5.504485701319105\n",
      "SubSGD iter. 65/499: loss=621.7283182406318, w0=44.80000000000003, w1=-5.354270551967738\n",
      "SubSGD iter. 66/499: loss=598.6971409763437, w0=45.500000000000036, w1=-5.993845511057141\n",
      "SubSGD iter. 67/499: loss=591.2466675373906, w0=46.20000000000004, w1=-6.04069332580145\n",
      "SubSGD iter. 68/499: loss=572.9493131298591, w0=46.90000000000004, w1=-5.38066525345277\n",
      "SubSGD iter. 69/499: loss=541.5623704707712, w0=46.20000000000004, w1=-4.486760041090685\n",
      "SubSGD iter. 70/499: loss=543.823259213773, w0=46.90000000000004, w1=-4.773602452812006\n",
      "SubSGD iter. 71/499: loss=530.297199392044, w0=47.600000000000044, w1=-4.47380683309916\n",
      "SubSGD iter. 72/499: loss=506.63912884876765, w0=48.30000000000005, w1=-3.206284618415564\n",
      "SubSGD iter. 73/499: loss=466.9452052256005, w0=47.600000000000044, w1=-2.03110499702659\n",
      "SubSGD iter. 74/499: loss=465.7674304986207, w0=46.90000000000004, w1=-1.3332454930247506\n",
      "SubSGD iter. 75/499: loss=473.41730848398737, w0=47.600000000000044, w1=-1.908370448040658\n",
      "SubSGD iter. 76/499: loss=463.8712492014563, w0=48.30000000000005, w1=-0.8497410378927333\n",
      "SubSGD iter. 77/499: loss=430.40057480822855, w0=49.00000000000005, w1=-1.274739027039528\n",
      "SubSGD iter. 78/499: loss=419.33012996369183, w0=49.70000000000005, w1=-0.7962478386945699\n",
      "SubSGD iter. 79/499: loss=395.6239864574358, w0=50.400000000000055, w1=-1.2624826493110866\n",
      "SubSGD iter. 80/499: loss=386.1178781398473, w0=49.70000000000005, w1=0.6842022388857871\n",
      "SubSGD iter. 81/499: loss=375.5850061788307, w0=50.400000000000055, w1=-0.3436671509556648\n",
      "SubSGD iter. 82/499: loss=372.9946317766224, w0=51.10000000000006, w1=0.8600133023618128\n",
      "SubSGD iter. 83/499: loss=341.29937788560864, w0=51.80000000000006, w1=1.7789011670787396\n",
      "SubSGD iter. 84/499: loss=314.83472154874704, w0=52.500000000000064, w1=1.354689242116736\n",
      "SubSGD iter. 85/499: loss=305.0875776974907, w0=53.20000000000007, w1=2.846844014303927\n",
      "SubSGD iter. 86/499: loss=273.79768400797286, w0=53.90000000000007, w1=2.2836057351014767\n",
      "SubSGD iter. 87/499: loss=266.12439579833136, w0=54.60000000000007, w1=3.5692942952230258\n",
      "SubSGD iter. 88/499: loss=239.22544163172566, w0=55.300000000000075, w1=2.42009871330266\n",
      "SubSGD iter. 89/499: loss=238.43403021420738, w0=54.60000000000007, w1=3.2268027441714247\n",
      "SubSGD iter. 90/499: loss=242.67832634325515, w0=55.300000000000075, w1=3.7687985661421424\n",
      "SubSGD iter. 91/499: loss=224.42742646183214, w0=56.00000000000008, w1=4.992429168234811\n",
      "SubSGD iter. 92/499: loss=200.9427456013401, w0=56.70000000000008, w1=5.430851698018266\n",
      "SubSGD iter. 93/499: loss=185.4570911563782, w0=57.400000000000084, w1=4.616251571813402\n",
      "SubSGD iter. 94/499: loss=180.97473540985285, w0=58.10000000000009, w1=4.133621275253832\n",
      "SubSGD iter. 95/499: loss=174.4882307548964, w0=58.80000000000009, w1=3.882220043849239\n",
      "SubSGD iter. 96/499: loss=166.47870546937565, w0=59.50000000000009, w1=4.443666110250511\n",
      "SubSGD iter. 97/499: loss=151.3470965603192, w0=60.200000000000095, w1=5.014546548172646\n",
      "SubSGD iter. 98/499: loss=136.94080131309525, w0=60.9000000000001, w1=5.272015331232514\n",
      "SubSGD iter. 99/499: loss=125.87368503946838, w0=61.6000000000001, w1=5.403013643965595\n",
      "SubSGD iter. 100/499: loss=116.37632544494788, w0=60.9000000000001, w1=6.486845273543678\n",
      "SubSGD iter. 101/499: loss=116.64063473477216, w0=61.6000000000001, w1=6.521877675853471\n",
      "SubSGD iter. 102/499: loss=107.96552603220567, w0=62.300000000000104, w1=6.286097347282567\n",
      "SubSGD iter. 103/499: loss=101.69309737805365, w0=63.00000000000011, w1=5.637852634657079\n",
      "SubSGD iter. 104/499: loss=99.11568552557213, w0=63.70000000000011, w1=6.145409645695399\n",
      "SubSGD iter. 105/499: loss=88.30355626258759, w0=64.4000000000001, w1=5.984079519849201\n",
      "SubSGD iter. 106/499: loss=83.0290685578577, w0=65.10000000000011, w1=6.15033975372834\n",
      "SubSGD iter. 107/499: loss=75.81591870752561, w0=65.80000000000011, w1=5.618278863535804\n",
      "SubSGD iter. 108/499: loss=74.3663902548327, w0=66.50000000000011, w1=6.301649199900132\n",
      "SubSGD iter. 109/499: loss=64.22687185764063, w0=67.20000000000012, w1=6.889824024193636\n",
      "SubSGD iter. 110/499: loss=55.66714518606735, w0=66.50000000000011, w1=8.009943381182143\n",
      "SubSGD iter. 111/499: loss=53.42376270516492, w0=67.20000000000012, w1=7.38909810990868\n",
      "SubSGD iter. 112/499: loss=52.501621981136616, w0=67.90000000000012, w1=8.13702569788563\n",
      "SubSGD iter. 113/499: loss=44.20523593663635, w0=68.60000000000012, w1=7.596977412183877\n",
      "SubSGD iter. 114/499: loss=43.70562542402167, w0=69.30000000000013, w1=8.385984141709367\n",
      "SubSGD iter. 115/499: loss=36.33462831115782, w0=68.60000000000012, w1=8.245463366401104\n",
      "SubSGD iter. 116/499: loss=40.101021405759276, w0=69.30000000000013, w1=8.256776961820888\n",
      "SubSGD iter. 117/499: loss=37.001121826717984, w0=70.00000000000013, w1=8.967534913667372\n",
      "SubSGD iter. 118/499: loss=30.99072193876562, w0=69.30000000000013, w1=9.181192987019159\n",
      "SubSGD iter. 119/499: loss=32.60022907056652, w0=68.60000000000012, w1=9.982363041000966\n",
      "SubSGD iter. 120/499: loss=32.518066141566806, w0=69.30000000000013, w1=10.147984477103886\n",
      "SubSGD iter. 121/499: loss=28.911799940955664, w0=70.00000000000013, w1=10.842281329182336\n",
      "SubSGD iter. 122/499: loss=24.28887036574371, w0=70.70000000000013, w1=11.66090413269738\n",
      "SubSGD iter. 123/499: loss=20.4041353655743, w0=71.40000000000013, w1=12.43625540269331\n",
      "SubSGD iter. 124/499: loss=17.72375943298192, w0=70.70000000000013, w1=13.130865894285574\n",
      "SubSGD iter. 125/499: loss=18.810950499812147, w0=71.40000000000013, w1=14.00972463604311\n",
      "SubSGD iter. 126/499: loss=17.3198146104913, w0=72.10000000000014, w1=13.021564273780585\n",
      "SubSGD iter. 127/499: loss=16.203562611194013, w0=71.40000000000013, w1=11.885547670770636\n",
      "SubSGD iter. 128/499: loss=18.45003879159598, w0=72.10000000000014, w1=13.717178635227066\n",
      "SubSGD iter. 129/499: loss=16.12680784051241, w0=72.80000000000014, w1=14.241751483294314\n",
      "SubSGD iter. 130/499: loss=15.798219096482127, w0=72.10000000000014, w1=15.39556988706048\n",
      "SubSGD iter. 131/499: loss=17.93386763071349, w0=71.40000000000013, w1=14.981634738685232\n",
      "SubSGD iter. 132/499: loss=18.30724344702824, w0=72.10000000000014, w1=13.70293318341577\n",
      "SubSGD iter. 133/499: loss=16.12352649364876, w0=71.40000000000013, w1=14.306506562013963\n",
      "SubSGD iter. 134/499: loss=17.521152408099667, w0=72.10000000000014, w1=14.835100148641017\n",
      "SubSGD iter. 135/499: loss=17.017150669544023, w0=72.80000000000014, w1=15.441721526768736\n",
      "SubSGD iter. 136/499: loss=17.432607179024206, w0=72.10000000000014, w1=15.095647885750433\n",
      "SubSGD iter. 137/499: loss=17.404236432898372, w0=71.40000000000013, w1=13.612746007621595\n",
      "SubSGD iter. 138/499: loss=17.188207109581906, w0=72.10000000000014, w1=13.194420582611901\n",
      "SubSGD iter. 139/499: loss=16.139308462901063, w0=72.80000000000014, w1=11.923193565395753\n",
      "SubSGD iter. 140/499: loss=16.71924283661113, w0=72.10000000000014, w1=13.36588477677279\n",
      "SubSGD iter. 141/499: loss=16.105091110272173, w0=72.80000000000014, w1=14.42149368372148\n",
      "SubSGD iter. 142/499: loss=15.951343301143137, w0=72.10000000000014, w1=14.878986906975413\n",
      "SubSGD iter. 143/499: loss=17.077597266361032, w0=71.40000000000013, w1=14.275310355592742\n",
      "SubSGD iter. 144/499: loss=17.495846169492676, w0=70.70000000000013, w1=14.778764152151517\n",
      "SubSGD iter. 145/499: loss=19.59387122726314, w0=71.40000000000013, w1=15.663497985157722\n",
      "SubSGD iter. 146/499: loss=19.563817808420968, w0=70.70000000000013, w1=15.669906894977942\n",
      "SubSGD iter. 147/499: loss=21.148579431614785, w0=70.00000000000013, w1=14.274934644622288\n",
      "SubSGD iter. 148/499: loss=21.127038128152293, w0=69.30000000000013, w1=12.957378007969199\n",
      "SubSGD iter. 149/499: loss=23.49801097510394, w0=70.00000000000013, w1=14.339595181770486\n",
      "SubSGD iter. 150/499: loss=21.18054811591151, w0=70.70000000000013, w1=14.461201020048422\n",
      "SubSGD iter. 151/499: loss=19.23176346663269, w0=71.40000000000013, w1=13.180907639941728\n",
      "SubSGD iter. 152/499: loss=17.22400029662985, w0=72.10000000000014, w1=12.663348622155311\n",
      "SubSGD iter. 153/499: loss=16.431837679836885, w0=72.80000000000014, w1=11.188401625642985\n",
      "SubSGD iter. 154/499: loss=18.132919953424185, w0=73.50000000000014, w1=10.73803575792263\n",
      "SubSGD iter. 155/499: loss=19.165517440222576, w0=74.20000000000014, w1=10.602917015309457\n",
      "SubSGD iter. 156/499: loss=19.934352481308814, w0=73.50000000000014, w1=11.52353226008734\n",
      "SubSGD iter. 157/499: loss=17.32044237777684, w0=74.20000000000014, w1=11.762325644498388\n",
      "SubSGD iter. 158/499: loss=17.271085232039976, w0=73.50000000000014, w1=12.399310252115596\n",
      "SubSGD iter. 159/499: loss=15.990756377816457, w0=72.80000000000014, w1=12.833852177136523\n",
      "SubSGD iter. 160/499: loss=15.716435077247798, w0=73.50000000000014, w1=13.670741646677394\n",
      "SubSGD iter. 161/499: loss=15.42536801929673, w0=72.80000000000014, w1=13.723665158546389\n",
      "SubSGD iter. 162/499: loss=15.537623806576653, w0=72.10000000000014, w1=14.418167442667364\n",
      "SubSGD iter. 163/499: loss=16.538961643102922, w0=71.40000000000013, w1=14.589618667236538\n",
      "SubSGD iter. 164/499: loss=17.795304066049123, w0=72.10000000000014, w1=13.632821856210947\n",
      "SubSGD iter. 165/499: loss=16.11033398981812, w0=71.40000000000013, w1=14.23479308392032\n",
      "SubSGD iter. 166/499: loss=17.464431537053446, w0=72.10000000000014, w1=14.984941582668352\n",
      "SubSGD iter. 167/499: loss=17.231470135896355, w0=72.80000000000014, w1=14.542478527049859\n",
      "SubSGD iter. 168/499: loss=16.072603224128233, w0=73.50000000000014, w1=15.118520075254864\n",
      "SubSGD iter. 169/499: loss=16.749967180334405, w0=72.80000000000014, w1=14.98461078472603\n",
      "SubSGD iter. 170/499: loss=16.64022686243168, w0=72.10000000000014, w1=14.833038482802102\n",
      "SubSGD iter. 171/499: loss=17.014358438229316, w0=72.80000000000014, w1=14.83501286160697\n",
      "SubSGD iter. 172/499: loss=16.426286964106488, w0=72.10000000000014, w1=14.996342987453167\n",
      "SubSGD iter. 173/499: loss=17.24869685871848, w0=71.40000000000013, w1=15.372487635209318\n",
      "SubSGD iter. 174/499: loss=18.97065712314266, w0=72.10000000000014, w1=15.143885138501805\n",
      "SubSGD iter. 175/499: loss=17.483348135943153, w0=71.40000000000013, w1=15.887410374266672\n",
      "SubSGD iter. 176/499: loss=20.077862827259075, w0=72.10000000000014, w1=16.394929284589974\n",
      "SubSGD iter. 177/499: loss=20.34785738248324, w0=72.80000000000014, w1=15.970662282346792\n",
      "SubSGD iter. 178/499: loss=18.610282911936917, w0=73.50000000000014, w1=15.447679141678877\n",
      "SubSGD iter. 179/499: loss=17.3435684187574, w0=74.20000000000014, w1=15.050766726497939\n",
      "SubSGD iter. 180/499: loss=17.03048233139831, w0=73.50000000000014, w1=15.2740164424424\n",
      "SubSGD iter. 181/499: loss=17.01688537501918, w0=74.20000000000014, w1=15.628282670301253\n",
      "SubSGD iter. 182/499: loss=18.10455356599883, w0=74.90000000000015, w1=14.882135787146504\n",
      "SubSGD iter. 183/499: loss=17.659026765828816, w0=74.20000000000014, w1=14.602660150079751\n",
      "SubSGD iter. 184/499: loss=16.42688232337778, w0=74.90000000000015, w1=14.50814043705807\n",
      "SubSGD iter. 185/499: loss=17.204463214210378, w0=74.20000000000014, w1=14.015276485371308\n",
      "SubSGD iter. 186/499: loss=15.93979096399499, w0=73.50000000000014, w1=13.77815933816363\n",
      "SubSGD iter. 187/499: loss=15.451657216444845, w0=72.80000000000014, w1=14.827635277984491\n",
      "SubSGD iter. 188/499: loss=16.416315336245585, w0=73.50000000000014, w1=15.251097335483365\n",
      "SubSGD iter. 189/499: loss=16.976024172287225, w0=72.80000000000014, w1=14.549663117306812\n",
      "SubSGD iter. 190/499: loss=16.080264572207255, w0=72.10000000000014, w1=15.018229159186507\n",
      "SubSGD iter. 191/499: loss=17.28212959770231, w0=71.40000000000013, w1=13.68732516986148\n",
      "SubSGD iter. 192/499: loss=17.20090966769882, w0=72.10000000000014, w1=14.31363891951258\n",
      "SubSGD iter. 193/499: loss=16.44632943317956, w0=71.40000000000013, w1=14.155876256119425\n",
      "SubSGD iter. 194/499: loss=17.407956900361036, w0=72.10000000000014, w1=13.98457924428627\n",
      "SubSGD iter. 195/499: loss=16.226057989949656, w0=72.80000000000014, w1=13.050393517554554\n",
      "SubSGD iter. 196/499: loss=15.600024707344687, w0=73.50000000000014, w1=12.637009016893243\n",
      "SubSGD iter. 197/499: loss=15.762196464872767, w0=72.80000000000014, w1=12.934836066608215\n",
      "SubSGD iter. 198/499: loss=15.65631246932107, w0=73.50000000000014, w1=13.439243390900224\n",
      "SubSGD iter. 199/499: loss=15.407940811202328, w0=74.20000000000014, w1=12.439366732025634\n",
      "SubSGD iter. 200/499: loss=16.337536128801286, w0=74.90000000000015, w1=11.849420378077598\n",
      "SubSGD iter. 201/499: loss=18.004557231904826, w0=75.60000000000015, w1=11.351293917073392\n",
      "SubSGD iter. 202/499: loss=20.309968428720158, w0=74.90000000000015, w1=11.781739773576708\n",
      "SubSGD iter. 203/499: loss=18.117186715942395, w0=74.20000000000014, w1=12.14236014825466\n",
      "SubSGD iter. 204/499: loss=16.69063210738091, w0=73.50000000000014, w1=12.660635611137094\n",
      "SubSGD iter. 205/499: loss=15.742565361123296, w0=72.80000000000014, w1=12.519456128912744\n",
      "SubSGD iter. 206/499: loss=15.968913427590788, w0=73.50000000000014, w1=13.193874968353759\n",
      "SubSGD iter. 207/499: loss=15.447973468103841, w0=74.20000000000014, w1=13.006067728992427\n",
      "SubSGD iter. 208/499: loss=15.908546191723376, w0=73.50000000000014, w1=13.333143259754047\n",
      "SubSGD iter. 209/499: loss=15.417863201002127, w0=72.80000000000014, w1=12.786167658379531\n",
      "SubSGD iter. 210/499: loss=15.748369519492305, w0=72.10000000000014, w1=13.568110285620357\n",
      "SubSGD iter. 211/499: loss=16.10251983238279, w0=71.40000000000013, w1=13.581947921273096\n",
      "SubSGD iter. 212/499: loss=17.184584191186076, w0=72.10000000000014, w1=14.913348115687656\n",
      "SubSGD iter. 213/499: loss=17.126268374870754, w0=71.40000000000013, w1=13.485172296962634\n",
      "SubSGD iter. 214/499: loss=17.179373048904598, w0=72.10000000000014, w1=13.075592274343656\n",
      "SubSGD iter. 215/499: loss=16.1802692945047, w0=72.80000000000014, w1=13.106517027190625\n",
      "SubSGD iter. 216/499: loss=15.577504747112048, w0=72.10000000000014, w1=13.140989739315987\n",
      "SubSGD iter. 217/499: loss=16.15597927466668, w0=72.80000000000014, w1=13.629196682513927\n",
      "SubSGD iter. 218/499: loss=15.519040111040168, w0=72.10000000000014, w1=12.415697998943358\n",
      "SubSGD iter. 219/499: loss=16.664676102441476, w0=72.80000000000014, w1=12.384078308731915\n",
      "SubSGD iter. 220/499: loss=16.108074410220745, w0=72.10000000000014, w1=11.385145549323537\n",
      "SubSGD iter. 221/499: loss=18.292217961647925, w0=71.40000000000013, w1=11.89958417084464\n",
      "SubSGD iter. 222/499: loss=18.427760809432215, w0=72.10000000000014, w1=12.020434621967718\n",
      "SubSGD iter. 223/499: loss=17.163358610172825, w0=71.40000000000013, w1=13.054401195411945\n",
      "SubSGD iter. 224/499: loss=17.269802969113517, w0=72.10000000000014, w1=12.24620328066796\n",
      "SubSGD iter. 225/499: loss=16.859385159281636, w0=71.40000000000013, w1=11.596041855551809\n",
      "SubSGD iter. 226/499: loss=18.953465569776924, w0=72.10000000000014, w1=12.181850940726521\n",
      "SubSGD iter. 227/499: loss=16.940834971529345, w0=71.40000000000013, w1=12.016338254261512\n",
      "SubSGD iter. 228/499: loss=18.250090140268203, w0=72.10000000000014, w1=12.530568954861037\n",
      "SubSGD iter. 229/499: loss=16.549049415319423, w0=72.80000000000014, w1=13.17205084705336\n",
      "SubSGD iter. 230/499: loss=15.555195167256684, w0=73.50000000000014, w1=12.266125868524167\n",
      "SubSGD iter. 231/499: loss=16.143518116589604, w0=72.80000000000014, w1=12.440488916469993\n",
      "SubSGD iter. 232/499: loss=16.047860101632697, w0=72.10000000000014, w1=12.552022851869582\n",
      "SubSGD iter. 233/499: loss=16.52891672369885, w0=72.80000000000014, w1=12.556525374047116\n",
      "SubSGD iter. 234/499: loss=15.93400451565643, w0=72.10000000000014, w1=12.51479578153909\n",
      "SubSGD iter. 235/499: loss=16.5641448164372, w0=71.40000000000013, w1=13.08275456503109\n",
      "SubSGD iter. 236/499: loss=17.258145919118988, w0=72.10000000000014, w1=13.322130912749424\n",
      "SubSGD iter. 237/499: loss=16.11102871046035, w0=71.40000000000013, w1=12.808556582420323\n",
      "SubSGD iter. 238/499: loss=17.404583233076835, w0=72.10000000000014, w1=13.085051582077865\n",
      "SubSGD iter. 239/499: loss=16.176491336794957, w0=71.40000000000013, w1=12.348849522432896\n",
      "SubSGD iter. 240/499: loss=17.8187836073557, w0=70.70000000000013, w1=10.966914780126492\n",
      "SubSGD iter. 241/499: loss=21.907179572473122, w0=71.40000000000013, w1=11.068932083505244\n",
      "SubSGD iter. 242/499: loss=20.085289095408392, w0=72.10000000000014, w1=10.136328927458798\n",
      "SubSGD iter. 243/499: loss=21.6877193815973, w0=72.80000000000014, w1=10.88928737134953\n",
      "SubSGD iter. 244/499: loss=18.86301834607703, w0=73.50000000000014, w1=9.779361169211041\n",
      "SubSGD iter. 245/499: loss=22.253421684510048, w0=74.20000000000014, w1=9.742785519621538\n",
      "SubSGD iter. 246/499: loss=22.778687923363144, w0=73.50000000000014, w1=10.022865726477365\n",
      "SubSGD iter. 247/499: loss=21.38201652251163, w0=72.80000000000014, w1=9.653955116622882\n",
      "SubSGD iter. 248/499: loss=22.826076870427265, w0=72.10000000000014, w1=8.924827846039921\n",
      "SubSGD iter. 249/499: loss=26.472099551707785, w0=72.80000000000014, w1=9.749676219610109\n",
      "SubSGD iter. 250/499: loss=22.464452424930354, w0=73.50000000000014, w1=10.126667379024873\n",
      "SubSGD iter. 251/499: loss=21.028577513100505, w0=74.20000000000014, w1=11.928115483231723\n",
      "SubSGD iter. 252/499: loss=17.000103088315377, w0=73.50000000000014, w1=11.969689596865507\n",
      "SubSGD iter. 253/499: loss=16.547206425264932, w0=74.20000000000014, w1=13.271454287907346\n",
      "SubSGD iter. 254/499: loss=15.818062265877021, w0=73.50000000000014, w1=13.330031385321405\n",
      "SubSGD iter. 255/499: loss=15.418324147752404, w0=72.80000000000014, w1=12.628951865255331\n",
      "SubSGD iter. 256/499: loss=15.869764114417947, w0=72.10000000000014, w1=13.378260454171848\n",
      "SubSGD iter. 257/499: loss=16.10375899459054, w0=72.80000000000014, w1=13.724019502417686\n",
      "SubSGD iter. 258/499: loss=15.537710312508917, w0=73.50000000000014, w1=14.343001426301013\n",
      "SubSGD iter. 259/499: loss=15.779755880697808, w0=74.20000000000014, w1=14.721115263966551\n",
      "SubSGD iter. 260/499: loss=16.566917029860736, w0=73.50000000000014, w1=14.432668048464492\n",
      "SubSGD iter. 261/499: loss=15.861184140064777, w0=72.80000000000014, w1=14.462727404292137\n",
      "SubSGD iter. 262/499: loss=15.991026555848112, w0=73.50000000000014, w1=15.341586146049673\n",
      "SubSGD iter. 263/499: loss=17.14040879740693, w0=74.20000000000014, w1=15.683460700754726\n",
      "SubSGD iter. 264/499: loss=18.224629747396683, w0=73.50000000000014, w1=16.088636867653992\n",
      "SubSGD iter. 265/499: loss=18.81036528711565, w0=72.80000000000014, w1=16.09973726166791\n",
      "SubSGD iter. 266/499: loss=18.94013238711793, w0=73.50000000000014, w1=15.79914832416703\n",
      "SubSGD iter. 267/499: loss=18.09701336144102, w0=72.80000000000014, w1=15.807080028977\n",
      "SubSGD iter. 268/499: loss=18.21618729968376, w0=73.50000000000014, w1=16.141870609346032\n",
      "SubSGD iter. 269/499: loss=18.95066501208545, w0=72.80000000000014, w1=15.894587890407415\n",
      "SubSGD iter. 270/499: loss=18.42367907350217, w0=72.10000000000014, w1=15.272198472206634\n",
      "SubSGD iter. 271/499: loss=17.705115839194676, w0=71.40000000000013, w1=16.083967730233784\n",
      "SubSGD iter. 272/499: loss=20.57043096526334, w0=70.70000000000013, w1=15.112994379891186\n",
      "SubSGD iter. 273/499: loss=20.083908501103423, w0=71.40000000000013, w1=15.938326376077978\n",
      "SubSGD iter. 274/499: loss=20.20174939951664, w0=70.70000000000013, w1=14.92184196282761\n",
      "SubSGD iter. 275/499: loss=19.789972332863695, w0=71.40000000000013, w1=15.452659538932554\n",
      "SubSGD iter. 276/499: loss=19.125618281337754, w0=72.10000000000014, w1=14.250702289437703\n",
      "SubSGD iter. 277/499: loss=16.395825420216052, w0=71.40000000000013, w1=14.384706287968925\n",
      "SubSGD iter. 278/499: loss=17.58886508082389, w0=72.10000000000014, w1=13.855055074385797\n",
      "SubSGD iter. 279/499: loss=16.169053790859326, w0=72.80000000000014, w1=14.259600745281677\n",
      "SubSGD iter. 280/499: loss=15.811980229176678, w0=73.50000000000014, w1=13.223741849733793\n",
      "SubSGD iter. 281/499: loss=15.439882409695553, w0=72.80000000000014, w1=12.390095189922656\n",
      "SubSGD iter. 282/499: loss=16.10150021128417, w0=72.10000000000014, w1=13.530197716399408\n",
      "SubSGD iter. 283/499: loss=16.099887124204216, w0=71.40000000000013, w1=13.538649079779645\n",
      "SubSGD iter. 284/499: loss=17.1810949079078, w0=70.70000000000013, w1=13.228849528511182\n",
      "SubSGD iter. 285/499: loss=18.781569644255015, w0=71.40000000000013, w1=12.953373320385882\n",
      "SubSGD iter. 286/499: loss=17.31787457563884, w0=70.70000000000013, w1=12.459595800854794\n",
      "SubSGD iter. 287/499: loss=19.270422518950458, w0=71.40000000000013, w1=11.713001947880315\n",
      "SubSGD iter. 288/499: loss=18.7399911164882, w0=70.70000000000013, w1=11.85593662904214\n",
      "SubSGD iter. 289/499: loss=20.068427479321016, w0=71.40000000000013, w1=12.814390307121053\n",
      "SubSGD iter. 290/499: loss=17.400684910773613, w0=70.70000000000013, w1=12.86948609693389\n",
      "SubSGD iter. 291/499: loss=18.93629163715986, w0=71.40000000000013, w1=13.327768143152518\n",
      "SubSGD iter. 292/499: loss=17.190901677769066, w0=72.10000000000014, w1=13.598679131939418\n",
      "SubSGD iter. 293/499: loss=16.105689279876316, w0=72.80000000000014, w1=13.745193013191424\n",
      "SubSGD iter. 294/499: loss=15.543107309612463, w0=72.10000000000014, w1=12.649887901912768\n",
      "SubSGD iter. 295/499: loss=16.4429171202323, w0=71.40000000000013, w1=12.089835787800418\n",
      "SubSGD iter. 296/499: loss=18.14523669105836, w0=72.10000000000014, w1=11.078634006436104\n",
      "SubSGD iter. 297/499: loss=18.9812015524158, w0=71.40000000000013, w1=11.443670376466095\n",
      "SubSGD iter. 298/499: loss=19.252091775895405, w0=72.10000000000014, w1=11.789628786383394\n",
      "SubSGD iter. 299/499: loss=17.526804112026774, w0=72.80000000000014, w1=12.740882052107496\n",
      "SubSGD iter. 300/499: loss=15.780802508245584, w0=72.10000000000014, w1=12.843043091633136\n",
      "SubSGD iter. 301/499: loss=16.30128666876929, w0=72.80000000000014, w1=13.205666150642942\n",
      "SubSGD iter. 302/499: loss=15.54541802389308, w0=72.10000000000014, w1=13.464939103031\n",
      "SubSGD iter. 303/499: loss=16.098721868053243, w0=72.80000000000014, w1=13.792881470326622\n",
      "SubSGD iter. 304/499: loss=15.556904763258267, w0=72.10000000000014, w1=14.527776533420042\n",
      "SubSGD iter. 305/499: loss=16.647831919594655, w0=72.80000000000014, w1=13.709697945040363\n",
      "SubSGD iter. 306/499: loss=15.534314008327911, w0=72.10000000000014, w1=13.731998614507583\n",
      "SubSGD iter. 307/499: loss=16.130436900572704, w0=72.80000000000014, w1=13.420357209902315\n",
      "SubSGD iter. 308/499: loss=15.509628862283678, w0=72.10000000000014, w1=13.745722458894027\n",
      "SubSGD iter. 309/499: loss=16.13399340879364, w0=71.40000000000013, w1=14.661456082605257\n",
      "SubSGD iter. 310/499: loss=17.87761716819884, w0=70.70000000000013, w1=15.019582275030897\n",
      "SubSGD iter. 311/499: loss=19.93570310746702, w0=71.40000000000013, w1=15.501500322303324\n",
      "SubSGD iter. 312/499: loss=19.223171274503578, w0=72.10000000000014, w1=15.051134454582968\n",
      "SubSGD iter. 313/499: loss=17.333296324216995, w0=71.40000000000013, w1=14.998902559737246\n",
      "SubSGD iter. 314/499: loss=18.33332746142444, w0=72.10000000000014, w1=16.088240399519396\n",
      "SubSGD iter. 315/499: loss=19.50082181325309, w0=72.80000000000014, w1=14.890635077903433\n",
      "SubSGD iter. 316/499: loss=16.503218693055388, w0=73.50000000000014, w1=14.538480670786852\n",
      "SubSGD iter. 317/499: loss=15.967617028004792, w0=72.80000000000014, w1=15.904728321756629\n",
      "SubSGD iter. 318/499: loss=18.44821836644871, w0=73.50000000000014, w1=16.71790527884705\n",
      "SubSGD iter. 319/499: loss=20.65006838644417, w0=74.20000000000014, w1=15.467921409349879\n",
      "SubSGD iter. 320/499: loss=17.772864000828537, w0=73.50000000000014, w1=15.349545027629233\n",
      "SubSGD iter. 321/499: loss=17.155258901687358, w0=72.80000000000014, w1=15.545348855093964\n",
      "SubSGD iter. 322/499: loss=17.64129425094306, w0=73.50000000000014, w1=15.98176030759011\n",
      "SubSGD iter. 323/499: loss=18.53724371783134, w0=72.80000000000014, w1=14.812649450983077\n",
      "SubSGD iter. 324/499: loss=16.39622788521466, w0=73.50000000000014, w1=15.65121720907854\n",
      "SubSGD iter. 325/499: loss=17.76483843138432, w0=72.80000000000014, w1=14.817570549267403\n",
      "SubSGD iter. 326/499: loss=16.402799507881348, w0=73.50000000000014, w1=14.670595100367285\n",
      "SubSGD iter. 327/499: loss=16.116222700786782, w0=72.80000000000014, w1=15.221807083065258\n",
      "SubSGD iter. 328/499: loss=17.025314222339013, w0=72.10000000000014, w1=14.990846012254456\n",
      "SubSGD iter. 329/499: loss=17.240375086554153, w0=71.40000000000013, w1=15.190829455496651\n",
      "SubSGD iter. 330/499: loss=18.643318872793618, w0=72.10000000000014, w1=14.278905873940515\n",
      "SubSGD iter. 331/499: loss=16.417967818816205, w0=71.40000000000013, w1=14.089673975923043\n",
      "SubSGD iter. 332/499: loss=17.3653846845675, w0=72.10000000000014, w1=13.881735881065666\n",
      "SubSGD iter. 333/499: loss=16.179424167982333, w0=72.80000000000014, w1=14.89831355830132\n",
      "SubSGD iter. 334/499: loss=16.51408191444255, w0=72.10000000000014, w1=14.148328959712806\n",
      "SubSGD iter. 335/499: loss=16.32213677095151, w0=71.40000000000013, w1=15.22094355088845\n",
      "SubSGD iter. 336/499: loss=18.69530104334635, w0=72.10000000000014, w1=14.775574040573423\n",
      "SubSGD iter. 337/499: loss=16.938241392798528, w0=71.40000000000013, w1=15.00907969769406\n",
      "SubSGD iter. 338/499: loss=18.34884025597513, w0=70.70000000000013, w1=15.347653559112539\n",
      "SubSGD iter. 339/499: loss=20.494705566927635, w0=70.00000000000013, w1=14.870798910581714\n",
      "SubSGD iter. 340/499: loss=21.778409738093725, w0=70.70000000000013, w1=13.764076986549634\n",
      "SubSGD iter. 341/499: loss=18.79053514442389, w0=71.40000000000013, w1=12.946324421746551\n",
      "SubSGD iter. 342/499: loss=17.3216095301936, w0=70.70000000000013, w1=13.323362724271506\n",
      "SubSGD iter. 343/499: loss=18.76232616135249, w0=70.00000000000013, w1=14.888582583976515\n",
      "SubSGD iter. 344/499: loss=21.803306495159294, w0=70.70000000000013, w1=14.394595990582287\n",
      "SubSGD iter. 345/499: loss=19.168609505479225, w0=70.00000000000013, w1=14.999662460830617\n",
      "SubSGD iter. 346/499: loss=21.965972987333213, w0=70.70000000000013, w1=15.638211184136983\n",
      "SubSGD iter. 347/499: loss=21.079661970368367, w0=70.00000000000013, w1=14.931048850162515\n",
      "SubSGD iter. 348/499: loss=21.864037641809603, w0=70.70000000000013, w1=14.451362917154839\n",
      "SubSGD iter. 349/499: loss=19.222155875078275, w0=70.00000000000013, w1=14.980932473232363\n",
      "SubSGD iter. 350/499: loss=21.937679748416944, w0=70.70000000000013, w1=15.546326720769603\n",
      "SubSGD iter. 351/499: loss=20.885550848427904, w0=71.40000000000013, w1=15.86094440544286\n",
      "SubSGD iter. 352/499: loss=20.014490992413887, w0=70.70000000000013, w1=15.182107842730293\n",
      "SubSGD iter. 353/499: loss=20.199178607481002, w0=70.00000000000013, w1=15.220303653456028\n",
      "SubSGD iter. 354/499: loss=22.325677841707492, w0=69.30000000000013, w1=15.99882934641163\n",
      "SubSGD iter. 355/499: loss=26.534569354986505, w0=70.00000000000013, w1=16.515569911837858\n",
      "SubSGD iter. 356/499: loss=25.419064256674726, w0=70.70000000000013, w1=16.80639081002551\n",
      "SubSGD iter. 357/499: loss=24.28349805079939, w0=70.00000000000013, w1=17.62549319180362\n",
      "SubSGD iter. 358/499: loss=29.404597988592332, w0=69.30000000000013, w1=16.48963277136641\n",
      "SubSGD iter. 359/499: loss=27.891404563947884, w0=70.00000000000013, w1=17.312406616471492\n",
      "SubSGD iter. 360/499: loss=28.15562129119001, w0=70.70000000000013, w1=17.426722884361133\n",
      "SubSGD iter. 361/499: loss=26.539549289057987, w0=70.00000000000013, w1=16.549420444541536\n",
      "SubSGD iter. 362/499: loss=25.522402578760673, w0=70.70000000000013, w1=16.01741064464427\n",
      "SubSGD iter. 363/499: loss=21.970059646975418, w0=71.40000000000013, w1=16.729305457902186\n",
      "SubSGD iter. 364/499: loss=22.459285551141093, w0=70.70000000000013, w1=16.424988764530774\n",
      "SubSGD iter. 365/499: loss=23.087429874011164, w0=71.40000000000013, w1=16.494419919014145\n",
      "SubSGD iter. 366/499: loss=21.723588750976685, w0=70.70000000000013, w1=15.840084870146327\n",
      "SubSGD iter. 367/499: loss=21.535782561656927, w0=70.00000000000013, w1=15.727577263959688\n",
      "SubSGD iter. 368/499: loss=23.33729709146692, w0=70.70000000000013, w1=15.30680975367961\n",
      "SubSGD iter. 369/499: loss=20.419245851314887, w0=71.40000000000013, w1=15.253009765723567\n",
      "SubSGD iter. 370/499: loss=18.7516498554533, w0=70.70000000000013, w1=15.015226409444717\n",
      "SubSGD iter. 371/499: loss=19.929005128206093, w0=71.40000000000013, w1=15.197169378562466\n",
      "SubSGD iter. 372/499: loss=18.65418732037249, w0=72.10000000000014, w1=16.579974108179435\n",
      "SubSGD iter. 373/499: loss=20.904423963511306, w0=72.80000000000014, w1=16.944630808835697\n",
      "SubSGD iter. 374/499: loss=21.51069700962119, w0=72.10000000000014, w1=16.21227344729803\n",
      "SubSGD iter. 375/499: loss=19.832057585380227, w0=71.40000000000013, w1=15.195789034047664\n",
      "SubSGD iter. 376/499: loss=18.65181759077651, w0=72.10000000000014, w1=14.664812656309625\n",
      "SubSGD iter. 377/499: loss=16.80084400967171, w0=71.40000000000013, w1=15.419973253884605\n",
      "SubSGD iter. 378/499: loss=19.061664166528853, w0=72.10000000000014, w1=14.634445009876575\n",
      "SubSGD iter. 379/499: loss=16.765316402137863, w0=72.80000000000014, w1=13.486223383683082\n",
      "SubSGD iter. 380/499: loss=15.507888537137584, w0=73.50000000000014, w1=13.040281800884715\n",
      "SubSGD iter. 381/499: loss=15.503671580532268, w0=72.80000000000014, w1=12.559900008761442\n",
      "SubSGD iter. 382/499: loss=15.930894790632488, w0=73.50000000000014, w1=13.074416328600329\n",
      "SubSGD iter. 383/499: loss=15.489254406364523, w0=74.20000000000014, w1=13.908244528635624\n",
      "SubSGD iter. 384/499: loss=15.888196415606624, w0=74.90000000000015, w1=14.969236850809239\n",
      "SubSGD iter. 385/499: loss=17.784972629152772, w0=74.20000000000014, w1=14.050254329882893\n",
      "SubSGD iter. 386/499: loss=15.959135564878597, w0=73.50000000000014, w1=14.650645465011465\n",
      "SubSGD iter. 387/499: loss=16.092664019836334, w0=72.80000000000014, w1=13.558161088977903\n",
      "SubSGD iter. 388/499: loss=15.510944436567463, w0=73.50000000000014, w1=13.681903079243153\n",
      "SubSGD iter. 389/499: loss=15.427562467749542, w0=72.80000000000014, w1=14.790178676414037\n",
      "SubSGD iter. 390/499: loss=16.3665282258684, w0=72.10000000000014, w1=15.81144434957116\n",
      "SubSGD iter. 391/499: loss=18.81709960312505, w0=72.80000000000014, w1=15.14105026710443\n",
      "SubSGD iter. 392/499: loss=16.88788903712005, w0=73.50000000000014, w1=15.7173221105914\n",
      "SubSGD iter. 393/499: loss=17.910570469612228, w0=74.20000000000014, w1=15.508679677042647\n",
      "SubSGD iter. 394/499: loss=17.85473057262736, w0=73.50000000000014, w1=15.030612953929072\n",
      "SubSGD iter. 395/499: loss=16.60976814926181, w0=72.80000000000014, w1=14.665288694350613\n",
      "SubSGD iter. 396/499: loss=16.210662874292012, w0=73.50000000000014, w1=14.670850474548034\n",
      "SubSGD iter. 397/499: loss=16.11652685407981, w0=74.20000000000014, w1=15.219313224019546\n",
      "SubSGD iter. 398/499: loss=17.309481990561828, w0=73.50000000000014, w1=15.318934219375796\n",
      "SubSGD iter. 399/499: loss=17.098490325518977, w0=72.80000000000014, w1=14.393002093440117\n",
      "SubSGD iter. 400/499: loss=15.92491634102797, w0=73.50000000000014, w1=14.63049653116834\n",
      "SubSGD iter. 401/499: loss=16.069273957447194, w0=72.80000000000014, w1=13.894103026373903\n",
      "SubSGD iter. 402/499: loss=15.593727122025273, w0=72.10000000000014, w1=14.230919841336723\n",
      "SubSGD iter. 403/499: loss=16.380769026060474, w0=72.80000000000014, w1=15.055836340420145\n",
      "SubSGD iter. 404/499: loss=16.749950623546816, w0=73.50000000000014, w1=13.567457507488546\n",
      "SubSGD iter. 405/499: loss=15.410971538311571, w0=72.80000000000014, w1=13.944030609814988\n",
      "SubSGD iter. 406/499: loss=15.61566302464798, w0=73.50000000000014, w1=14.55945152344575\n",
      "SubSGD iter. 407/499: loss=15.990040189008251, w0=74.20000000000014, w1=14.801599232195409\n",
      "SubSGD iter. 408/499: loss=16.67006889027831, w0=73.50000000000014, w1=14.420090482607103\n",
      "SubSGD iter. 409/499: loss=15.84927737565857, w0=72.80000000000014, w1=14.415217343268676\n",
      "SubSGD iter. 410/499: loss=15.94545205761877, w0=72.10000000000014, w1=13.569713234359444\n",
      "SubSGD iter. 411/499: loss=16.102662814328326, w0=71.40000000000013, w1=14.03212507468159\n",
      "SubSGD iter. 412/499: loss=17.331938006104256, w0=72.10000000000014, w1=12.791509251860557\n",
      "SubSGD iter. 413/499: loss=16.33542455301876, w0=72.80000000000014, w1=12.217935067306046\n",
      "SubSGD iter. 414/499: loss=16.303908403709652, w0=72.10000000000014, w1=12.841792539714877\n",
      "SubSGD iter. 415/499: loss=16.302083638777972, w0=72.80000000000014, w1=13.167091600726616\n",
      "SubSGD iter. 416/499: loss=15.5567332339186, w0=73.50000000000014, w1=12.627380909657777\n",
      "SubSGD iter. 417/499: loss=15.770356453974358, w0=72.80000000000014, w1=13.379530765713996\n",
      "SubSGD iter. 418/499: loss=15.5128855243405, w0=72.10000000000014, w1=14.000930107421244\n",
      "SubSGD iter. 419/499: loss=16.23444667341249, w0=72.80000000000014, w1=13.969332199131632\n",
      "SubSGD iter. 420/499: loss=15.627731097630656, w0=72.10000000000014, w1=14.75303098564479\n",
      "SubSGD iter. 421/499: loss=16.90928280810669, w0=72.80000000000014, w1=14.784675113236629\n",
      "SubSGD iter. 422/499: loss=16.359331136720687, w0=73.50000000000014, w1=14.789177635414163\n",
      "SubSGD iter. 423/499: loss=16.264471494999793, w0=74.20000000000014, w1=14.448446902530442\n",
      "SubSGD iter. 424/499: loss=16.265599772265414, w0=73.50000000000014, w1=13.566681650611681\n",
      "SubSGD iter. 425/499: loss=15.410903761670605, w0=72.80000000000014, w1=12.52046718072576\n",
      "SubSGD iter. 426/499: loss=15.967943069824452, w0=73.50000000000014, w1=11.986651912967769\n",
      "SubSGD iter. 427/499: loss=16.521736800646828, w0=72.80000000000014, w1=12.601910274319456\n",
      "SubSGD iter. 428/499: loss=15.893135657549236, w0=73.50000000000014, w1=13.313317101390108\n",
      "SubSGD iter. 429/499: loss=15.420965642959349, w0=74.20000000000014, w1=12.33066682422465\n",
      "SubSGD iter. 430/499: loss=16.456529445772524, w0=74.90000000000015, w1=11.672996754728818\n",
      "SubSGD iter. 431/499: loss=18.30774191113964, w0=74.20000000000014, w1=12.725932503649094\n",
      "SubSGD iter. 432/499: loss=16.080468630409502, w0=74.90000000000015, w1=13.203448200330943\n",
      "SubSGD iter. 433/499: loss=16.713792100166156, w0=74.20000000000014, w1=13.925128201316205\n",
      "SubSGD iter. 434/499: loss=15.895574140410469, w0=73.50000000000014, w1=14.39441910379223\n",
      "SubSGD iter. 435/499: loss=15.825466084414106, w0=74.20000000000014, w1=15.037709948295099\n",
      "SubSGD iter. 436/499: loss=17.01005466369799, w0=74.90000000000015, w1=14.62238150391092\n",
      "SubSGD iter. 437/499: loss=17.328477437025924, w0=74.20000000000014, w1=14.898061751986397\n",
      "SubSGD iter. 438/499: loss=16.802233930477485, w0=74.90000000000015, w1=13.7631128091729\n",
      "SubSGD iter. 439/499: loss=16.715789022534313, w0=74.20000000000014, w1=13.423898289593735\n",
      "SubSGD iter. 440/499: loss=15.797934147377164, w0=74.90000000000015, w1=14.144675962837034\n",
      "SubSGD iter. 441/499: loss=16.896719383174553, w0=74.20000000000014, w1=13.776991104921283\n",
      "SubSGD iter. 442/499: loss=15.840563841762405, w0=74.90000000000015, w1=14.406472234133272\n",
      "SubSGD iter. 443/499: loss=17.105072999145456, w0=75.60000000000015, w1=14.976209541776196\n",
      "SubSGD iter. 444/499: loss=19.16463753032816, w0=76.30000000000015, w1=15.585919116687627\n",
      "SubSGD iter. 445/499: loss=22.12219362655936, w0=75.60000000000015, w1=16.188440094671854\n",
      "SubSGD iter. 446/499: loss=21.713488502182347, w0=74.90000000000015, w1=17.3392619550521\n",
      "SubSGD iter. 447/499: loss=24.123692385399995, w0=75.60000000000015, w1=17.191202632674134\n",
      "SubSGD iter. 448/499: loss=24.93246547877325, w0=76.30000000000015, w1=16.73524965217653\n",
      "SubSGD iter. 449/499: loss=25.203401619789894, w0=75.60000000000015, w1=15.714097599048616\n",
      "SubSGD iter. 450/499: loss=20.54112426570176, w0=76.30000000000015, w1=15.682477908837173\n",
      "SubSGD iter. 451/499: loss=22.330228199932165, w0=75.60000000000015, w1=15.629968041184888\n",
      "SubSGD iter. 452/499: loss=20.356685321005322, w0=76.30000000000015, w1=15.280786024983394\n",
      "SubSGD iter. 453/499: loss=21.52607337183105, w0=75.60000000000015, w1=16.41405521813903\n",
      "SubSGD iter. 454/499: loss=22.350069519529196, w0=74.90000000000015, w1=16.603202609586702\n",
      "SubSGD iter. 455/499: loss=21.553726571894575, w0=75.60000000000015, w1=16.263739375047244\n",
      "SubSGD iter. 456/499: loss=21.92028873650191, w0=76.30000000000015, w1=16.687160097256267\n",
      "SubSGD iter. 457/499: loss=25.04800058663521, w0=75.60000000000015, w1=15.885350811628891\n",
      "SubSGD iter. 458/499: loss=20.938433734598195, w0=74.90000000000015, w1=16.019560286192718\n",
      "SubSGD iter. 459/499: loss=19.901044690122486, w0=75.60000000000015, w1=15.734996539342372\n",
      "SubSGD iter. 460/499: loss=20.5880389306914, w0=74.90000000000015, w1=15.564375047910046\n",
      "SubSGD iter. 461/499: loss=18.848540241345837, w0=75.60000000000015, w1=16.113832857286667\n",
      "SubSGD iter. 462/499: loss=21.514180934599697, w0=74.90000000000015, w1=15.550044514383409\n",
      "SubSGD iter. 463/499: loss=18.818768595975225, w0=74.20000000000014, w1=15.904587708261804\n",
      "SubSGD iter. 464/499: loss=18.73638658342887, w0=74.90000000000015, w1=15.592946303656536\n",
      "SubSGD iter. 465/499: loss=18.90850982833221, w0=75.60000000000015, w1=14.949475494992301\n",
      "SubSGD iter. 466/499: loss=19.124987461292076, w0=74.90000000000015, w1=15.4375389351876\n",
      "SubSGD iter. 467/499: loss=18.592173438930388, w0=74.20000000000014, w1=15.790244479288972\n",
      "SubSGD iter. 468/499: loss=18.465655701832457, w0=74.90000000000015, w1=14.991830902092087\n",
      "SubSGD iter. 469/499: loss=17.818882265767552, w0=75.60000000000015, w1=13.978643552780271\n",
      "SubSGD iter. 470/499: loss=18.16935186516721, w0=74.90000000000015, w1=14.25425243204037\n",
      "SubSGD iter. 471/499: loss=16.97558724000667, w0=75.60000000000015, w1=14.58334320473179\n",
      "SubSGD iter. 472/499: loss=18.653886172978492, w0=74.90000000000015, w1=15.134470076951121\n",
      "SubSGD iter. 473/499: loss=18.044742563306475, w0=74.20000000000014, w1=14.394960407316294\n",
      "SubSGD iter. 474/499: loss=16.21521596338863, w0=74.90000000000015, w1=14.642863160241019\n",
      "SubSGD iter. 475/499: loss=17.352090941317634, w0=75.60000000000015, w1=14.955119675039052\n",
      "SubSGD iter. 476/499: loss=19.133298997012986, w0=74.90000000000015, w1=14.390085640854217\n",
      "SubSGD iter. 477/499: loss=17.090020823469146, w0=75.60000000000015, w1=14.407524443155634\n",
      "SubSGD iter. 478/499: loss=18.475303296266073, w0=76.30000000000015, w1=13.716028576434116\n",
      "SubSGD iter. 479/499: loss=19.93206299289724, w0=75.60000000000015, w1=14.891153598074206\n",
      "SubSGD iter. 480/499: loss=19.040968813442596, w0=74.90000000000015, w1=15.27491331130509\n",
      "SubSGD iter. 481/499: loss=18.287004229653476, w0=74.20000000000014, w1=14.09176721155422\n",
      "SubSGD iter. 482/499: loss=15.983682062722178, w0=73.50000000000014, w1=13.277294007661895\n",
      "SubSGD iter. 483/499: loss=15.427608549298398, w0=72.80000000000014, w1=12.632865835276425\n",
      "SubSGD iter. 484/499: loss=15.866441922633545, w0=73.50000000000014, w1=12.21524816607306\n",
      "SubSGD iter. 485/499: loss=16.206556883120214, w0=72.80000000000014, w1=13.401035119938527\n",
      "SubSGD iter. 486/499: loss=15.510962400862907, w0=73.50000000000014, w1=11.941474750955829\n",
      "SubSGD iter. 487/499: loss=16.590209525727538, w0=74.20000000000014, w1=12.70339910634031\n",
      "SubSGD iter. 488/499: loss=16.097707730082902, w0=73.50000000000014, w1=12.851813074509039\n",
      "SubSGD iter. 489/499: loss=15.6042507428832, w0=72.80000000000014, w1=14.560683056008159\n",
      "SubSGD iter. 490/499: loss=16.09211608266435, w0=73.50000000000014, w1=14.530066146293853\n",
      "SubSGD iter. 491/499: loss=15.95874339886348, w0=74.20000000000014, w1=14.620001388758318\n",
      "SubSGD iter. 492/499: loss=16.446505987008173, w0=73.50000000000014, w1=14.266398066482246\n",
      "SubSGD iter. 493/499: loss=15.716559080836518, w0=72.80000000000014, w1=14.27537136945186\n",
      "SubSGD iter. 494/499: loss=15.824403910906375, w0=73.50000000000014, w1=13.287622146939277\n",
      "SubSGD iter. 495/499: loss=15.425571278819122, w0=74.20000000000014, w1=13.773084961530156\n",
      "SubSGD iter. 496/499: loss=15.839410257628623, w0=74.90000000000015, w1=13.774715102736254\n",
      "SubSGD iter. 497/499: loss=16.719144423479516, w0=75.60000000000015, w1=14.318222092063325\n",
      "SubSGD iter. 498/499: loss=18.396434957520423, w0=74.90000000000015, w1=14.727146083507977\n",
      "SubSGD iter. 499/499: loss=17.453676490219163, w0=74.20000000000014, w1=15.061210304010745\n",
      "SubSGD: execution time=0.070 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f822df13c164d8eaa8d817760961451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
